{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train RNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    ")\n",
    "\n",
    "from data.dataset import FeatureDataset\n",
    "from params import *\n",
    "from data.preparation import *\n",
    "from util.logger import Config as ConfigInf\n",
    "from training.main_lvl2 import k_fold\n",
    "from util.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_lvl2 import define_model\n",
    "from training.losses import StudyLoss\n",
    "from util.metrics import rsna_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_lvl2()\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(\"../input/train_folded_v1.csv\")\n",
    "    df = df.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['fold'] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = {\n",
    "    # \"scs_crop\": \"../logs/2024-08-29/15/\",  # 15\n",
    "    # \"nfn_crop\": \"../logs/2024-08-29/16/\",  # 30\n",
    "    \"scs_crop_coords\":  \"../logs/2024-08-29/17/\",\n",
    "    # \"nfn_crop_coords\":  \"../logs/2024-08-29/18/\",\n",
    "    \"ss_crop_coords\": \"../logs/2024-09-10/11/\", \n",
    "\n",
    "    # \"dh\": '../output/oof____cfg_dh_12s4c.pth',  # Darragh preds\n",
    "    # \"ch\": '../output/oof_cfg_ch_35.pth',  # Dieter preds\n",
    "    \"crop\": \"../logs/2024-08-29/5/\",  # 75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigInf(json.load(open(EXP_FOLDERS[\"crop\"] + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FeatureDataset(df, EXP_FOLDERS, targets=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     p_ = dataset[i][0][\"nfn_crop_coords\"].view(-1, 3).numpy()\n",
    "#     # p_ = p_.reshape(5, 2, 3).transpose(1, 0, 2).reshape(10, 3)\n",
    "#     p.append(p_)\n",
    "# p = np.array(p)\n",
    "\n",
    "# y = df[df.columns[8:18]].values\n",
    "\n",
    "# aucs = []\n",
    "# for i, c in enumerate(CLASSES[5:15]):\n",
    "#     auc = disk_auc(y[:, i], p[:, i])\n",
    "#     print(f'{c} AUC: \\t {auc :.4f}')\n",
    "#     aucs.append(auc)\n",
    "# print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    fts, y, _ = dataset[i]\n",
    "    # for k in fts:\n",
    "    #     print(k, fts[k].size())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "fts, y, _ = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in fts:\n",
    "    print(k, fts[k].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# for i in range(5):\n",
    "#     plt.plot(fts['ss_aux'].softmax(1)[:, i], label=LEVELS[i])\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# for i in [1, 2]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'left_{i}')\n",
    "# for i in [4, 5]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'right_{i - 3}')\n",
    "# plt.legend()\n",
    "\n",
    "# # plt.subplot(1, 3, 3)\n",
    "# # for i in range(5):\n",
    "# #     plt.plot(fts['ss'][:, 1, i], label=LEVELS[i])\n",
    "# # plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in fts:\n",
    "#     print(k, fts[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = define_model(\n",
    "#     name=\"simple\",\n",
    "#     num_classes=len(CLASSES) * 3,\n",
    "#     layer_dim=0,\n",
    "#     ft_dim=64,\n",
    "#     n_fts=45 + 75,\n",
    "#     resize=10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = {k: fts[k].unsqueeze(0) for k in fts}\n",
    "\n",
    "# pred, _ = model(x)\n",
    "# pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "    targets = CLASSES\n",
    "\n",
    "    # Data\n",
    "    exp_folders = {\n",
    "        # \"scs_crop\": \"../logs/2024-08-29/15/\",  # 15\n",
    "        # \"nfn_crop\": \"../logs/2024-08-29/16/\",  # 30\n",
    "        # \"scs_crop_coords\":  \"../logs/2024-08-29/17/\",\n",
    "        # \"nfn_crop_coords\":  \"../logs/2024-08-29/18/\",\n",
    "\n",
    "        # # \"scs_crop_coords\": \"../logs/2024-09-12/1/\",  # 5f -0.005 scs\n",
    "        \"scs_crop_coords_2\": \"../logs/2024-09-12/9/\",  # 3f -0.005 scs\n",
    "    \n",
    "        \"dh\": '../output/oof____cfg_dh_12s4c.pth',  # Darragh preds\n",
    "        \"dh_2\": \"../output/oof____cfg_dh_19a.pth\",  # Darragh preds\n",
    "        # # \"dh\": \"../output/oof____cfg_dh_15c.pth\",  # Darragh preds\n",
    "        # # \"dh\": \"../output/oof____cfg_dh_15c_2seed.pth\",  # Darragh preds\n",
    "        \n",
    "        \"ch\": '../output/oof_cfg_ch_35.pth',  # Dieter preds\n",
    "\n",
    "        # \"crop\": \"../logs/2024-09-12/21/\",  # coatnet side 5fs2\n",
    "        \"crop\": \"../logs/2024-09-13/7/\",  # coatnet side 7fs2  <---- best\n",
    "        # \"crop_2\": \"../logs/2024-09-13/1/\",  # coatnet side 7fs2\n",
    "\n",
    "    }\n",
    "    n_fts = 0\n",
    "    resize = 0\n",
    "    remove_noisy = False\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = \"../input/train_folded_v1.csv\"  # f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "    name = \"simple\"\n",
    "    dense_dim = 4096\n",
    "    layer_dim = 0\n",
    "    ft = 6 + 3 * (\"dh\" in exp_folders) + 3 * (\"ch\" in exp_folders)\n",
    "    ft_dim = [\n",
    "        ft + 3 * len([k for k in exp_folders if \"scs\" in k]),\n",
    "        ft + 3 * len([k for k in exp_folders if \"nfn\" in k]),\n",
    "        ft + 3 * len([k for k in exp_folders if \"nfn\" in k]),\n",
    "    ]  # scs, nfn, ss\n",
    "\n",
    "    p = 0.\n",
    "    num_classes = len(CLASSES) * 3\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"study\",\n",
    "        \"weighted\": True,\n",
    "        \"use_any\": True,\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"study\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 128,\n",
    "        \"val_bs\": 512,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"sched\": False,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_classes_aux\": num_classes_aux,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 7e-5,  # 5e-5\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        \"weight_decay\": 1,\n",
    "    }\n",
    "\n",
    "    epochs = 15\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 20\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "\n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_lvl2()\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(Config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\")\n",
    "\n",
    "# df = df[~df['study_id'].isin([1215498865, 1647904243, 2570933394, 2761048584, 3284652867, 3941522676])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds = k_fold(Config, df, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss, losses = rsna_loss(df[Config.targets].values, preds)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "print(f'\\n -> CV Score : {avg_loss :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scs_loss\t: 0.267\n",
    "- nfn_loss\t: 0.484\n",
    "- ss_loss\t: 0.552\n",
    "- any_loss\t: 0.264\n",
    "\n",
    " -> CV Score : 0.3915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(\"../logs/2024-09-09/2/pred_oof.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yy = pkl[\"target\"].contiguous()[order].cpu().numpy().clip(-1, 2)\n",
    "# for i in range(len(df)):\n",
    "#     if not (df[Config.targets].values[i] == yy[i]).all():\n",
    "#         print(i, yy[i].tolist(), df[Config.targets].values[i].tolist())\n",
    "#         display(df.iloc[[i]])\n",
    "#         # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl = torch.load('../output/oof_cfg_ch_35.pth')\n",
    "# pkl = torch.load('../output/oof____cfg_dh_12s1.pth')\n",
    "\n",
    "# df = df[~df['study_id'].isin([1215498865, 1647904243, 2570933394, 2761048584, 3284652867, 3941522676])].reset_index(drop=True)\n",
    "\n",
    "# order = [pkl['study_id'].tolist().index(s) for s in df['study_id'].values]\n",
    "\n",
    "# avg_loss, losses = rsna_loss(df[Config.targets].values, pkl[\"logits\"].cpu().float().softmax(-1).numpy()[order])\n",
    "\n",
    "# for k, v in losses.items():\n",
    "#     print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "# print(f'\\n -> CV Score : {avg_loss :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aucs = []\n",
    "# for i, c in enumerate(CLASSES):\n",
    "#     auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "#     print(f'{c} AUC: \\t {auc :.4f}')\n",
    "#     aucs.append(auc)\n",
    "# print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aucs = []\n",
    "# for i, c in enumerate(CLASSES):\n",
    "#     auc = disk_auc(df[Config.targets].values[:, i], preds_dd[:, i])\n",
    "#     print(f'{c} AUC: \\t {auc :.4f}')\n",
    "#     aucs.append(auc)\n",
    "# print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = preds[df['fold'].values == 0]\n",
    "# df = df[df['fold'].values == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = preds.reshape(preds.shape[0], 5, 5, 3)\n",
    "p = p.transpose(0, 2, 1, 3)\n",
    "p = p.reshape(-1, 5, 3)\n",
    "\n",
    "y = df[Config.targets].values\n",
    "y = y.reshape(preds.shape[0], 5, 5)\n",
    "y = y.transpose(0, 2, 1)\n",
    "y = y.reshape(-1, 5)\n",
    "\n",
    "aucs = []\n",
    "for i, c in enumerate(CLASSES_CROP):\n",
    "    auc = disk_auc(y[:, i], p[:, i])\n",
    "    print(f'{c} AUC: \\t {auc :.4f}')\n",
    "    aucs.append(auc)\n",
    "print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(LEVELS_):\n",
    "    print(c, disk_auc(y[:, i], p[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [5, 6, 7, 8, 9, 15, 16, 17, 18, 19]:\n",
    "    j = i + 5\n",
    "    c = CLASSES[i]\n",
    "    c2 = CLASSES[j]\n",
    "    \n",
    "    ref_auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "    auc = disk_auc(df[Config.targets].values[:, i], preds[:, j])\n",
    "    r = (\n",
    "        spearmanr(preds[:, i][:, 1], preds[:, j][:, 1]).statistic + \n",
    "        spearmanr(preds[:, i][:, 2], preds[:, j][:, 2]).statistic\n",
    "    ) / 2\n",
    "    print(f'\\npred: {c2} \\t truth: {c}')\n",
    "    # print(r)\n",
    "    y1 = df[Config.targets].values[:, i]\n",
    "    y2 = df[Config.targets].values[:, j]\n",
    "    \n",
    "    eq = (y1[(y1 > 0) & (y2 > 0)] == y2[(y1 > 0) & (y2 > 0)]).mean()\n",
    "    print(f'Ref AUC          : {ref_auc :.4f}')\n",
    "    print(f'Swap AUC         : {auc :.4f}')\n",
    "    print(f'Equal proportion : {eq:.3f}')\n",
    "    print(f'Preds correlation: {r:.3f}')\n",
    "\n",
    "\n",
    "# for j in [5, 6, 7, 8, 9, 15, 16, 17, 18, 19]:\n",
    "#     i = j + 5\n",
    "#     c = CLASSES[i]\n",
    "#     c2 = CLASSES[j]\n",
    "    \n",
    "#     ref_auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "#     auc = disk_auc(df[Config.targets].values[:, i], preds[:, j])\n",
    "#     r = (\n",
    "#         spearmanr(preds[:, i][:, 1], preds[:, j][:, 1]).statistic + \n",
    "#         spearmanr(preds[:, i][:, 2], preds[:, j][:, 2]).statistic\n",
    "#     ) / 2\n",
    "#     print(f'\\npred: {c2} \\t truth: {c}')\n",
    "#     # print(r)\n",
    "#     y1 = df[Config.targets].values[:, i]\n",
    "#     y2 = df[Config.targets].values[:, j]\n",
    "    \n",
    "#     eq = (y1[(y1 > 0) & (y2 > 0)] == y2[(y1 > 0) & (y2 > 0)]).mean()\n",
    "#     print(f'Ref AUC          : {ref_auc :.4f}')\n",
    "#     print(f'Swap AUC         : {auc :.4f}')\n",
    "#     print(f'Equal proportion : {eq:.3f}')\n",
    "#     print(f'Preds correlation: {r:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "y = df[Config.targets].values\n",
    "for i in tqdm(range(len(df))):\n",
    "    l = rsna_loss(y[i:i+1], preds[i:i+1])[1]\n",
    "    l.update({\"study\": df[\"study_id\"].values[i]})\n",
    "    losses.append(l)\n",
    "losses = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i, c in enumerate(losses.columns[:-1]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    sns.histplot(losses[c].values)\n",
    "    plt.title(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[losses[\"scs\"] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"study_id\"] == 1972129014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[losses[\"any\"] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scs_loss\t: 0.325\n",
    "- nfn_loss\t: 0.517\n",
    "- ss_loss\t: 0.634\n",
    "- any_loss\t: 0.297\n",
    "\n",
    " -> CV Score : 0.443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
