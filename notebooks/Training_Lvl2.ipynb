{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train RNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tviel/work/kaggle_rsna_lumbar_spine/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    ")\n",
    "\n",
    "from data.dataset import FeatureDataset\n",
    "from params import *\n",
    "from data.preparation import *\n",
    "from util.logger import Config as ConfigInf\n",
    "from training.main_lvl2 import k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_lvl2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(\"../input/folds_4.csv\")\n",
    "    df = df.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>[702807833, 1054713880, 2448190387]</td>\n",
       "      <td>[Sagittal T2/STIR, Sagittal T1, Axial T2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>[3201256954, 3486248476, 3666319702]</td>\n",
       "      <td>[Axial T2, Sagittal T1, Sagittal T2/STIR]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>[132939515, 1951927562, 3219733239]</td>\n",
       "      <td>[Sagittal T2/STIR, Axial T2, Sagittal T1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                             series_id  \\\n",
       "0   4003253   [702807833, 1054713880, 2448190387]   \n",
       "1   4646740  [3201256954, 3486248476, 3666319702]   \n",
       "2   7143189   [132939515, 1951927562, 3219733239]   \n",
       "\n",
       "                          series_description  spinal_canal_stenosis_l1_l2  \\\n",
       "0  [Sagittal T2/STIR, Sagittal T1, Axial T2]                            0   \n",
       "1  [Axial T2, Sagittal T1, Sagittal T2/STIR]                            0   \n",
       "2  [Sagittal T2/STIR, Axial T2, Sagittal T1]                            0   \n",
       "\n",
       "   spinal_canal_stenosis_l2_l3  spinal_canal_stenosis_l3_l4  \\\n",
       "0                            0                            0   \n",
       "1                            0                            1   \n",
       "2                            0                            0   \n",
       "\n",
       "   spinal_canal_stenosis_l4_l5  spinal_canal_stenosis_l5_s1  \\\n",
       "0                            0                            0   \n",
       "1                            2                            0   \n",
       "2                            0                            0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l2_l3  ...  \\\n",
       "0                                      0  ...   \n",
       "1                                      0  ...   \n",
       "2                                      0  ...   \n",
       "\n",
       "   left_subarticular_stenosis_l2_l3  left_subarticular_stenosis_l3_l4  \\\n",
       "0                                 0                                 0   \n",
       "1                                 0                                 0   \n",
       "2                                 0                                 0   \n",
       "\n",
       "   left_subarticular_stenosis_l4_l5  left_subarticular_stenosis_l5_s1  \\\n",
       "0                                 1                                 0   \n",
       "1                                 2                                 0   \n",
       "2                                 0                                 0   \n",
       "\n",
       "   right_subarticular_stenosis_l1_l2  right_subarticular_stenosis_l2_l3  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  1   \n",
       "2                                  0                                  0   \n",
       "\n",
       "   right_subarticular_stenosis_l3_l4  right_subarticular_stenosis_l4_l5  \\\n",
       "0                                  0                                  0   \n",
       "1                                  1                                  1   \n",
       "2                                  0                                  0   \n",
       "\n",
       "   right_subarticular_stenosis_l5_s1  fold  \n",
       "0                                  0     0  \n",
       "1                                  0     0  \n",
       "2                                  0     3  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = {\n",
    "    \"nfn\": \"../logs/2024-08-05/27/\",\n",
    "    \"scs\": \"../logs/2024-08-04/33/\",\n",
    "    \"ss\": \"../logs/2024-08-06/17/\",  # NEEDS IMPROVEMENT\n",
    "    \"ss_aux\": \"../logs/2024-08-06/17/\",\n",
    "    \"scs_crop\": \"../logs/2024-08-07/19/\",\n",
    "    \"nfn_crop\": \"../logs/2024-08-07/32/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigInf(json.load(open(EXP_FOLDERS[\"nfn\"] + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>[702807833, 1054713880, 2448190387]</td>\n",
       "      <td>[Sagittal T2/STIR, Sagittal T1, Axial T2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id                            series_id  \\\n",
       "0   4003253  [702807833, 1054713880, 2448190387]   \n",
       "\n",
       "                          series_description  spinal_canal_stenosis_l1_l2  \\\n",
       "0  [Sagittal T2/STIR, Sagittal T1, Axial T2]                            0   \n",
       "\n",
       "   spinal_canal_stenosis_l2_l3  spinal_canal_stenosis_l3_l4  \\\n",
       "0                            0                            0   \n",
       "\n",
       "   spinal_canal_stenosis_l4_l5  spinal_canal_stenosis_l5_s1  \\\n",
       "0                            0                            0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                                      0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l2_l3  ...  \\\n",
       "0                                      0  ...   \n",
       "\n",
       "   left_subarticular_stenosis_l2_l3  left_subarticular_stenosis_l3_l4  \\\n",
       "0                                 0                                 0   \n",
       "\n",
       "   left_subarticular_stenosis_l4_l5  left_subarticular_stenosis_l5_s1  \\\n",
       "0                                 1                                 0   \n",
       "\n",
       "   right_subarticular_stenosis_l1_l2  right_subarticular_stenosis_l2_l3  \\\n",
       "0                                  0                                  0   \n",
       "\n",
       "   right_subarticular_stenosis_l3_l4  right_subarticular_stenosis_l4_l5  \\\n",
       "0                                  0                                  0   \n",
       "\n",
       "   right_subarticular_stenosis_l5_s1  fold  \n",
       "0                                  0     0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FeatureDataset(df, EXP_FOLDERS, resize=15, targets=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b8c007679649029f986d7c28212cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    fts, y, _ = dataset[i]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fts, y, _ = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfn torch.Size([15, 15])\n",
      "scs torch.Size([15, 15])\n",
      "ss torch.Size([30, 6])\n",
      "ss_aux torch.Size([30, 5])\n",
      "scs_crop torch.Size([15])\n",
      "nfn_crop torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "for k in fts:\n",
    "    print(k, fts[k].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# for i in range(5):\n",
    "#     plt.plot(fts['ss_aux'].softmax(1)[:, i], label=LEVELS[i])\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# for i in [1, 2]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'left_{i}')\n",
    "# for i in [4, 5]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'right_{i - 3}')\n",
    "# plt.legend()\n",
    "\n",
    "# # plt.subplot(1, 3, 3)\n",
    "# # for i in range(5):\n",
    "# #     plt.plot(fts['ss'][:, 1, i], label=LEVELS[i])\n",
    "# # plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in fts:\n",
    "#     print(k, fts[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_lvl2 import define_model\n",
    "from training.losses import StudyLoss\n",
    "from util.metrics import rsna_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\n",
    "    name=\"baseline\",\n",
    "    num_classes=len(CLASSES) * 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {k: fts[k].unsqueeze(0) for k in fts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = model(x)\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9375, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = StudyLoss()\n",
    "l(pred, y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9375256299972534,\n",
       " {'scs': 1.110085,\n",
       "  'nfn': 1.0883645,\n",
       "  'ss': 1.1093023,\n",
       "  'any': 0.44235074520111084})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsna_loss(y.unsqueeze(0).numpy(), pred.softmax(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "    targets = CLASSES\n",
    "\n",
    "    # Data\n",
    "    exp_folders = {\n",
    "        \"nfn\": \"../logs/2024-08-05/27/\",\n",
    "        \"scs\": \"../logs/2024-08-04/33/\",\n",
    "        \"ss\": \"../logs/2024-08-06/17/\",  # NEEDS IMPROVEMENT\n",
    "        \"ss_aux\": \"../logs/2024-08-06/17/\",\n",
    "        # \"scs_crop\": \"../logs/2024-08-07/19/\",\n",
    "        # \"nfn_crop\": \"../logs/2024-08-07/32/\",\n",
    "        \"scs_crop\": \"../logs/2024-08-08/7/\",\n",
    "        \"nfn_crop\": \"../logs/2024-08-08/6/\",\n",
    "    }\n",
    "    n_fts = 1\n",
    "    resize = 10\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "    name = \"baseline\"\n",
    "    dense_dim = 1024\n",
    "    layer_dim = 8\n",
    "    ft_dim = 0\n",
    "\n",
    "    p = 0.1\n",
    "    num_classes = len(CLASSES) * 3\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"study\",\n",
    "        \"weighted\": True,\n",
    "        \"use_any\": True,\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"study\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"val_bs\": 512,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"sched\": False,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_classes_aux\": num_classes_aux,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 1e-4,\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        \"weight_decay\": 1,\n",
    "    }\n",
    "\n",
    "    epochs = 20\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 20\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "\n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Fold 1 / 4  -------------\n",
      "\n",
      "    -> 1481 training studies\n",
      "    -> 494 validation studies\n",
      "    -> 5354443 trainable parameters\n",
      "\n",
      "Epoch 01/20 (step 0020) \tlr=9.6e-05 \t t=1s \t loss=0.743    scs_loss=0.594    nfn_loss=0.668    ss_loss=0.810    any_loss=0.427\t val_loss=0.625\n",
      "Epoch 02/20 (step 0040) \tlr=9.2e-05 \t t=1s \t loss=0.577    scs_loss=0.510    nfn_loss=0.613    ss_loss=0.722    any_loss=0.386\t val_loss=0.557\n",
      "Epoch 03/20 (step 0060) \tlr=8.7e-05 \t t=1s \t loss=0.514    scs_loss=0.477    nfn_loss=0.596    ss_loss=0.698    any_loss=0.392\t val_loss=0.541\n",
      "Epoch 04/20 (step 0080) \tlr=8.3e-05 \t t=1s \t loss=0.506    scs_loss=0.450    nfn_loss=0.585    ss_loss=0.680    any_loss=0.379\t val_loss=0.523\n",
      "Epoch 05/20 (step 0100) \tlr=7.8e-05 \t t=1s \t loss=0.469    scs_loss=0.417    nfn_loss=0.570    ss_loss=0.677    any_loss=0.368\t val_loss=0.508\n",
      "Epoch 06/20 (step 0120) \tlr=7.4e-05 \t t=1s \t loss=0.460    scs_loss=0.390    nfn_loss=0.562    ss_loss=0.667    any_loss=0.373\t val_loss=0.498\n",
      "Epoch 07/20 (step 0140) \tlr=7.0e-05 \t t=1s \t loss=0.442    scs_loss=0.376    nfn_loss=0.555    ss_loss=0.659    any_loss=0.364\t val_loss=0.489\n",
      "Epoch 07/20 (step 0160) \tlr=6.5e-05 \t t=0s \t loss=0.434    scs_loss=0.365    nfn_loss=0.547    ss_loss=0.658    any_loss=0.368\t val_loss=0.484\n",
      "Epoch 08/20 (step 0180) \tlr=6.1e-05 \t t=1s \t loss=0.425    scs_loss=0.374    nfn_loss=0.542    ss_loss=0.655    any_loss=0.364\t val_loss=0.484\n",
      "Epoch 09/20 (step 0200) \tlr=5.7e-05 \t t=1s \t loss=0.418    scs_loss=0.358    nfn_loss=0.536    ss_loss=0.651    any_loss=0.366\t val_loss=0.478\n",
      "Epoch 10/20 (step 0220) \tlr=5.2e-05 \t t=1s \t loss=0.408    scs_loss=0.361    nfn_loss=0.536    ss_loss=0.651    any_loss=0.365\t val_loss=0.478\n",
      "Epoch 11/20 (step 0240) \tlr=4.8e-05 \t t=1s \t loss=0.416    scs_loss=0.353    nfn_loss=0.533    ss_loss=0.648    any_loss=0.362\t val_loss=0.474\n",
      "Epoch 12/20 (step 0260) \tlr=4.4e-05 \t t=1s \t loss=0.391    scs_loss=0.360    nfn_loss=0.530    ss_loss=0.643    any_loss=0.364\t val_loss=0.474\n",
      "Epoch 13/20 (step 0280) \tlr=3.9e-05 \t t=1s \t loss=0.404    scs_loss=0.356    nfn_loss=0.526    ss_loss=0.648    any_loss=0.368\t val_loss=0.475\n",
      "Epoch 13/20 (step 0300) \tlr=3.5e-05 \t t=0s \t loss=0.395    scs_loss=0.355    nfn_loss=0.525    ss_loss=0.641    any_loss=0.365\t val_loss=0.471\n",
      "Epoch 14/20 (step 0320) \tlr=3.1e-05 \t t=1s \t loss=0.396    scs_loss=0.356    nfn_loss=0.523    ss_loss=0.640    any_loss=0.373\t val_loss=0.473\n",
      "Epoch 15/20 (step 0340) \tlr=2.6e-05 \t t=1s \t loss=0.378    scs_loss=0.354    nfn_loss=0.523    ss_loss=0.643    any_loss=0.367\t val_loss=0.472\n",
      "Epoch 16/20 (step 0360) \tlr=2.2e-05 \t t=1s \t loss=0.396    scs_loss=0.357    nfn_loss=0.523    ss_loss=0.641    any_loss=0.380\t val_loss=0.475\n",
      "Epoch 17/20 (step 0380) \tlr=1.8e-05 \t t=1s \t loss=0.390    scs_loss=0.356    nfn_loss=0.520    ss_loss=0.640    any_loss=0.377\t val_loss=0.473\n",
      "Epoch 18/20 (step 0400) \tlr=1.3e-05 \t t=1s \t loss=0.381    scs_loss=0.355    nfn_loss=0.519    ss_loss=0.639    any_loss=0.374\t val_loss=0.472\n",
      "Epoch 19/20 (step 0420) \tlr=8.9e-06 \t t=1s \t loss=0.380    scs_loss=0.357    nfn_loss=0.520    ss_loss=0.639    any_loss=0.376\t val_loss=0.473\n",
      "Epoch 20/20 (step 0440) \tlr=4.6e-06 \t t=1s \t loss=0.386    scs_loss=0.356    nfn_loss=0.519    ss_loss=0.638    any_loss=0.375\t val_loss=0.472\n",
      "Epoch 20/20 (step 0461) \tlr=0.0e+00 \t t=0s \t loss=0.382    scs_loss=0.356    nfn_loss=0.519    ss_loss=0.639    any_loss=0.376\t val_loss=0.473\n",
      "\n",
      "-------------   Fold 2 / 4  -------------\n",
      "\n",
      "    -> 1481 training studies\n",
      "    -> 494 validation studies\n",
      "    -> 5354443 trainable parameters\n",
      "\n",
      "Epoch 01/20 (step 0020) \tlr=9.6e-05 \t t=1s \t loss=0.741    scs_loss=0.637    nfn_loss=0.690    ss_loss=0.841    any_loss=0.386\t val_loss=0.639\n",
      "Epoch 02/20 (step 0040) \tlr=9.2e-05 \t t=1s \t loss=0.594    scs_loss=0.525    nfn_loss=0.611    ss_loss=0.732    any_loss=0.312\t val_loss=0.545\n",
      "Epoch 03/20 (step 0060) \tlr=8.7e-05 \t t=1s \t loss=0.539    scs_loss=0.438    nfn_loss=0.587    ss_loss=0.692    any_loss=0.306\t val_loss=0.506\n",
      "Epoch 04/20 (step 0080) \tlr=8.3e-05 \t t=1s \t loss=0.489    scs_loss=0.379    nfn_loss=0.575    ss_loss=0.678    any_loss=0.278\t val_loss=0.477\n",
      "Epoch 05/20 (step 0100) \tlr=7.8e-05 \t t=1s \t loss=0.477    scs_loss=0.360    nfn_loss=0.563    ss_loss=0.660    any_loss=0.268\t val_loss=0.463\n",
      "Epoch 06/20 (step 0120) \tlr=7.4e-05 \t t=1s \t loss=0.470    scs_loss=0.359    nfn_loss=0.552    ss_loss=0.651    any_loss=0.254\t val_loss=0.454\n",
      "Epoch 07/20 (step 0140) \tlr=7.0e-05 \t t=1s \t loss=0.458    scs_loss=0.339    nfn_loss=0.541    ss_loss=0.647    any_loss=0.261\t val_loss=0.447\n",
      "Epoch 07/20 (step 0160) \tlr=6.5e-05 \t t=0s \t loss=0.453    scs_loss=0.333    nfn_loss=0.536    ss_loss=0.640    any_loss=0.247\t val_loss=0.439\n",
      "Epoch 08/20 (step 0180) \tlr=6.1e-05 \t t=1s \t loss=0.441    scs_loss=0.335    nfn_loss=0.528    ss_loss=0.634    any_loss=0.243\t val_loss=0.435\n",
      "Epoch 09/20 (step 0200) \tlr=5.7e-05 \t t=1s \t loss=0.438    scs_loss=0.321    nfn_loss=0.527    ss_loss=0.635    any_loss=0.243\t val_loss=0.431\n",
      "Epoch 10/20 (step 0220) \tlr=5.2e-05 \t t=1s \t loss=0.430    scs_loss=0.317    nfn_loss=0.523    ss_loss=0.627    any_loss=0.235\t val_loss=0.426\n",
      "Epoch 11/20 (step 0240) \tlr=4.8e-05 \t t=1s \t loss=0.434    scs_loss=0.322    nfn_loss=0.518    ss_loss=0.625    any_loss=0.241\t val_loss=0.427\n",
      "Epoch 12/20 (step 0260) \tlr=4.4e-05 \t t=1s \t loss=0.414    scs_loss=0.317    nfn_loss=0.519    ss_loss=0.625    any_loss=0.239\t val_loss=0.425\n",
      "Epoch 13/20 (step 0280) \tlr=3.9e-05 \t t=1s \t loss=0.424    scs_loss=0.311    nfn_loss=0.514    ss_loss=0.621    any_loss=0.241\t val_loss=0.422\n",
      "Epoch 13/20 (step 0300) \tlr=3.5e-05 \t t=0s \t loss=0.415    scs_loss=0.316    nfn_loss=0.512    ss_loss=0.620    any_loss=0.242\t val_loss=0.422\n",
      "Epoch 14/20 (step 0320) \tlr=3.1e-05 \t t=1s \t loss=0.412    scs_loss=0.309    nfn_loss=0.513    ss_loss=0.620    any_loss=0.237\t val_loss=0.420\n",
      "Epoch 15/20 (step 0340) \tlr=2.6e-05 \t t=1s \t loss=0.417    scs_loss=0.308    nfn_loss=0.510    ss_loss=0.616    any_loss=0.241\t val_loss=0.419\n",
      "Epoch 16/20 (step 0360) \tlr=2.2e-05 \t t=1s \t loss=0.418    scs_loss=0.310    nfn_loss=0.510    ss_loss=0.619    any_loss=0.242\t val_loss=0.420\n",
      "Epoch 17/20 (step 0380) \tlr=1.8e-05 \t t=1s \t loss=0.400    scs_loss=0.306    nfn_loss=0.510    ss_loss=0.616    any_loss=0.239\t val_loss=0.418\n",
      "Epoch 18/20 (step 0400) \tlr=1.3e-05 \t t=1s \t loss=0.413    scs_loss=0.310    nfn_loss=0.508    ss_loss=0.616    any_loss=0.243\t val_loss=0.419\n",
      "Epoch 19/20 (step 0420) \tlr=8.9e-06 \t t=1s \t loss=0.397    scs_loss=0.307    nfn_loss=0.507    ss_loss=0.615    any_loss=0.240\t val_loss=0.417\n",
      "Epoch 20/20 (step 0440) \tlr=4.6e-06 \t t=1s \t loss=0.412    scs_loss=0.307    nfn_loss=0.508    ss_loss=0.616    any_loss=0.239\t val_loss=0.417\n",
      "Epoch 20/20 (step 0461) \tlr=0.0e+00 \t t=0s \t loss=0.405    scs_loss=0.307    nfn_loss=0.508    ss_loss=0.615    any_loss=0.240\t val_loss=0.417\n",
      "\n",
      "-------------   Fold 3 / 4  -------------\n",
      "\n",
      "    -> 1481 training studies\n",
      "    -> 494 validation studies\n",
      "    -> 5354443 trainable parameters\n",
      "\n",
      "Epoch 01/20 (step 0020) \tlr=9.6e-05 \t t=1s \t loss=0.747    scs_loss=0.547    nfn_loss=0.695    ss_loss=0.840    any_loss=0.410\t val_loss=0.623\n",
      "Epoch 02/20 (step 0040) \tlr=9.2e-05 \t t=1s \t loss=0.574    scs_loss=0.443    nfn_loss=0.616    ss_loss=0.722    any_loss=0.362\t val_loss=0.536\n",
      "Epoch 03/20 (step 0060) \tlr=8.7e-05 \t t=1s \t loss=0.514    scs_loss=0.405    nfn_loss=0.589    ss_loss=0.684    any_loss=0.349\t val_loss=0.507\n",
      "Epoch 04/20 (step 0080) \tlr=8.3e-05 \t t=1s \t loss=0.499    scs_loss=0.375    nfn_loss=0.576    ss_loss=0.672    any_loss=0.310\t val_loss=0.483\n",
      "Epoch 05/20 (step 0100) \tlr=7.8e-05 \t t=1s \t loss=0.479    scs_loss=0.357    nfn_loss=0.565    ss_loss=0.660    any_loss=0.306\t val_loss=0.472\n",
      "Epoch 06/20 (step 0120) \tlr=7.4e-05 \t t=1s \t loss=0.470    scs_loss=0.356    nfn_loss=0.554    ss_loss=0.654    any_loss=0.293\t val_loss=0.464\n",
      "Epoch 07/20 (step 0140) \tlr=7.0e-05 \t t=1s \t loss=0.454    scs_loss=0.327    nfn_loss=0.540    ss_loss=0.651    any_loss=0.293\t val_loss=0.453\n",
      "Epoch 07/20 (step 0160) \tlr=6.5e-05 \t t=0s \t loss=0.446    scs_loss=0.327    nfn_loss=0.536    ss_loss=0.643    any_loss=0.310\t val_loss=0.454\n",
      "Epoch 08/20 (step 0180) \tlr=6.1e-05 \t t=1s \t loss=0.428    scs_loss=0.319    nfn_loss=0.532    ss_loss=0.643    any_loss=0.282\t val_loss=0.444\n",
      "Epoch 09/20 (step 0200) \tlr=5.7e-05 \t t=1s \t loss=0.435    scs_loss=0.322    nfn_loss=0.527    ss_loss=0.641    any_loss=0.286\t val_loss=0.444\n",
      "Epoch 10/20 (step 0220) \tlr=5.2e-05 \t t=1s \t loss=0.424    scs_loss=0.324    nfn_loss=0.527    ss_loss=0.637    any_loss=0.302\t val_loss=0.447\n",
      "Epoch 11/20 (step 0240) \tlr=4.8e-05 \t t=1s \t loss=0.415    scs_loss=0.312    nfn_loss=0.518    ss_loss=0.636    any_loss=0.303\t val_loss=0.442\n",
      "Epoch 12/20 (step 0260) \tlr=4.4e-05 \t t=1s \t loss=0.415    scs_loss=0.311    nfn_loss=0.520    ss_loss=0.636    any_loss=0.280\t val_loss=0.436\n",
      "Epoch 13/20 (step 0280) \tlr=3.9e-05 \t t=1s \t loss=0.413    scs_loss=0.313    nfn_loss=0.515    ss_loss=0.634    any_loss=0.284\t val_loss=0.436\n",
      "Epoch 13/20 (step 0300) \tlr=3.5e-05 \t t=0s \t loss=0.408    scs_loss=0.312    nfn_loss=0.515    ss_loss=0.634    any_loss=0.298\t val_loss=0.440\n",
      "Epoch 14/20 (step 0320) \tlr=3.1e-05 \t t=1s \t loss=0.408    scs_loss=0.310    nfn_loss=0.513    ss_loss=0.632    any_loss=0.284\t val_loss=0.435\n",
      "Epoch 15/20 (step 0340) \tlr=2.6e-05 \t t=1s \t loss=0.400    scs_loss=0.308    nfn_loss=0.511    ss_loss=0.632    any_loss=0.283\t val_loss=0.434\n",
      "Epoch 16/20 (step 0360) \tlr=2.2e-05 \t t=1s \t loss=0.399    scs_loss=0.309    nfn_loss=0.510    ss_loss=0.631    any_loss=0.282\t val_loss=0.433\n",
      "Epoch 17/20 (step 0380) \tlr=1.8e-05 \t t=1s \t loss=0.398    scs_loss=0.310    nfn_loss=0.509    ss_loss=0.631    any_loss=0.285\t val_loss=0.434\n",
      "Epoch 18/20 (step 0400) \tlr=1.3e-05 \t t=1s \t loss=0.397    scs_loss=0.310    nfn_loss=0.508    ss_loss=0.630    any_loss=0.297\t val_loss=0.436\n",
      "Epoch 19/20 (step 0420) \tlr=8.9e-06 \t t=1s \t loss=0.394    scs_loss=0.309    nfn_loss=0.507    ss_loss=0.630    any_loss=0.283\t val_loss=0.432\n",
      "Epoch 20/20 (step 0440) \tlr=4.6e-06 \t t=1s \t loss=0.397    scs_loss=0.309    nfn_loss=0.507    ss_loss=0.630    any_loss=0.283\t val_loss=0.432\n",
      "Epoch 20/20 (step 0461) \tlr=0.0e+00 \t t=0s \t loss=0.395    scs_loss=0.309    nfn_loss=0.507    ss_loss=0.630    any_loss=0.285\t val_loss=0.433\n",
      "\n",
      "-------------   Fold 4 / 4  -------------\n",
      "\n",
      "    -> 1482 training studies\n",
      "    -> 493 validation studies\n",
      "    -> 5354443 trainable parameters\n",
      "\n",
      "Epoch 01/20 (step 0020) \tlr=9.6e-05 \t t=1s \t loss=0.739    scs_loss=0.601    nfn_loss=0.705    ss_loss=0.819    any_loss=0.387\t val_loss=0.628\n",
      "Epoch 02/20 (step 0040) \tlr=9.2e-05 \t t=1s \t loss=0.569    scs_loss=0.522    nfn_loss=0.627    ss_loss=0.728    any_loss=0.349\t val_loss=0.557\n",
      "Epoch 03/20 (step 0060) \tlr=8.7e-05 \t t=1s \t loss=0.512    scs_loss=0.427    nfn_loss=0.601    ss_loss=0.700    any_loss=0.342\t val_loss=0.517\n",
      "Epoch 04/20 (step 0080) \tlr=8.3e-05 \t t=1s \t loss=0.492    scs_loss=0.391    nfn_loss=0.588    ss_loss=0.687    any_loss=0.325\t val_loss=0.498\n",
      "Epoch 05/20 (step 0100) \tlr=7.8e-05 \t t=1s \t loss=0.473    scs_loss=0.375    nfn_loss=0.575    ss_loss=0.682    any_loss=0.306\t val_loss=0.484\n",
      "Epoch 06/20 (step 0120) \tlr=7.4e-05 \t t=1s \t loss=0.463    scs_loss=0.358    nfn_loss=0.567    ss_loss=0.669    any_loss=0.301\t val_loss=0.474\n",
      "Epoch 07/20 (step 0140) \tlr=7.0e-05 \t t=1s \t loss=0.454    scs_loss=0.350    nfn_loss=0.562    ss_loss=0.664    any_loss=0.299\t val_loss=0.469\n",
      "Epoch 07/20 (step 0160) \tlr=6.5e-05 \t t=0s \t loss=0.435    scs_loss=0.357    nfn_loss=0.554    ss_loss=0.661    any_loss=0.292\t val_loss=0.466\n",
      "Epoch 08/20 (step 0180) \tlr=6.1e-05 \t t=1s \t loss=0.437    scs_loss=0.343    nfn_loss=0.552    ss_loss=0.656    any_loss=0.290\t val_loss=0.460\n",
      "Epoch 09/20 (step 0200) \tlr=5.7e-05 \t t=1s \t loss=0.423    scs_loss=0.334    nfn_loss=0.552    ss_loss=0.658    any_loss=0.286\t val_loss=0.457\n",
      "Epoch 10/20 (step 0220) \tlr=5.2e-05 \t t=1s \t loss=0.411    scs_loss=0.334    nfn_loss=0.548    ss_loss=0.650    any_loss=0.291\t val_loss=0.456\n",
      "Epoch 11/20 (step 0240) \tlr=4.8e-05 \t t=1s \t loss=0.420    scs_loss=0.335    nfn_loss=0.543    ss_loss=0.650    any_loss=0.294\t val_loss=0.456\n",
      "Epoch 12/20 (step 0260) \tlr=4.4e-05 \t t=1s \t loss=0.410    scs_loss=0.328    nfn_loss=0.543    ss_loss=0.650    any_loss=0.288\t val_loss=0.452\n",
      "Epoch 13/20 (step 0280) \tlr=3.9e-05 \t t=1s \t loss=0.405    scs_loss=0.329    nfn_loss=0.541    ss_loss=0.647    any_loss=0.286\t val_loss=0.451\n",
      "Epoch 13/20 (step 0300) \tlr=3.5e-05 \t t=0s \t loss=0.404    scs_loss=0.327    nfn_loss=0.540    ss_loss=0.646    any_loss=0.287\t val_loss=0.450\n",
      "Epoch 14/20 (step 0320) \tlr=3.1e-05 \t t=1s \t loss=0.403    scs_loss=0.325    nfn_loss=0.538    ss_loss=0.646    any_loss=0.287\t val_loss=0.449\n",
      "Epoch 15/20 (step 0340) \tlr=2.6e-05 \t t=1s \t loss=0.396    scs_loss=0.327    nfn_loss=0.537    ss_loss=0.645    any_loss=0.291\t val_loss=0.450\n",
      "Epoch 16/20 (step 0360) \tlr=2.2e-05 \t t=1s \t loss=0.394    scs_loss=0.328    nfn_loss=0.536    ss_loss=0.645    any_loss=0.287\t val_loss=0.449\n",
      "Epoch 17/20 (step 0380) \tlr=1.8e-05 \t t=1s \t loss=0.401    scs_loss=0.321    nfn_loss=0.535    ss_loss=0.645    any_loss=0.288\t val_loss=0.447\n",
      "Epoch 18/20 (step 0400) \tlr=1.3e-05 \t t=1s \t loss=0.390    scs_loss=0.326    nfn_loss=0.535    ss_loss=0.644    any_loss=0.287\t val_loss=0.448\n",
      "Epoch 19/20 (step 0420) \tlr=8.9e-06 \t t=1s \t loss=0.392    scs_loss=0.324    nfn_loss=0.535    ss_loss=0.643    any_loss=0.287\t val_loss=0.447\n",
      "Epoch 20/20 (step 0440) \tlr=4.6e-06 \t t=1s \t loss=0.391    scs_loss=0.324    nfn_loss=0.535    ss_loss=0.643    any_loss=0.288\t val_loss=0.447\n",
      "Epoch 20/20 (step 0461) \tlr=0.0e+00 \t t=0s \t loss=0.389    scs_loss=0.324    nfn_loss=0.535    ss_loss=0.643    any_loss=0.288\t val_loss=0.447\n",
      "\n",
      "- scs_loss\t: 0.324\n",
      "- nfn_loss\t: 0.517\n",
      "- ss_loss\t: 0.632\n",
      "- any_loss\t: 0.298\n",
      "\n",
      " -> CV Score : 0.4427\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds = k_fold(Config, df, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- scs_loss\t: 0.322\n",
      "- nfn_loss\t: 0.516\n",
      "- ss_loss\t: 0.631\n",
      "- any_loss\t: 0.299\n",
      "\n",
      " -> CV Score : 0.442\n"
     ]
    }
   ],
   "source": [
    "avg_loss, losses = rsna_loss(df[Config.targets].values, preds)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scs_loss\t: 0.325\n",
    "- nfn_loss\t: 0.517\n",
    "- ss_loss\t: 0.634\n",
    "- any_loss\t: 0.297\n",
    "\n",
    " -> CV Score : 0.443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
