{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train RNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    ")\n",
    "\n",
    "from data.dataset import FeatureDataset\n",
    "from params import *\n",
    "from data.preparation import *\n",
    "from util.logger import Config as ConfigInf\n",
    "from training.main_lvl2 import k_fold\n",
    "from util.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_lvl2 import define_model\n",
    "from training.losses import StudyLoss\n",
    "from util.metrics import rsna_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_lvl2()\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(\"../input/folds_4.csv\")\n",
    "    df = df.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(\"../input/folds_4.csv\")\n",
    "    df = df.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = {\n",
    "    \"nfn\": \"../logs/2024-08-05/27/\",\n",
    "    \"scs\": \"../logs/2024-08-04/33/\",\n",
    "    \"ss\": \"../logs/2024-08-06/17/\",  # NEEDS IMPROVEMENT\n",
    "    # \"ss_aux\": \"../logs/2024-08-06/17/\",\n",
    "    \"scs_crop\": \"../logs/2024-08-07/19/\",\n",
    "    \"nfn_crop\": \"../logs/2024-08-07/32/\",\n",
    "    # \"ss_crop\": \"../logs/2024-08-20/5/\",\n",
    "    # \"scs_crop_coords\": \"../logs/2024-08-13/1/\",\n",
    "    # \"nfn_crop_coords\": \"../logs/2024-08-13/8/\",\n",
    "    \"crop\": \"../logs/2024-08-21/9/\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigInf(json.load(open(EXP_FOLDERS[\"nfn\"] + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df = df.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FeatureDataset(df, EXP_FOLDERS, resize=10, targets=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    fts, y, _ = dataset[i]\n",
    "    for k in fts:\n",
    "        print(k, fts[k].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fts, y, _ = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in fts:\n",
    "    print(k, fts[k].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# for i in range(5):\n",
    "#     plt.plot(fts['ss_aux'].softmax(1)[:, i], label=LEVELS[i])\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# for i in [1, 2]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'left_{i}')\n",
    "# for i in [4, 5]:\n",
    "#     plt.plot(fts['ss'][:, i], label=f'right_{i - 3}')\n",
    "# plt.legend()\n",
    "\n",
    "# # plt.subplot(1, 3, 3)\n",
    "# # for i in range(5):\n",
    "# #     plt.plot(fts['ss'][:, 1, i], label=LEVELS[i])\n",
    "# # plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in fts:\n",
    "#     print(k, fts[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\n",
    "    name=\"baseline\",\n",
    "    num_classes=len(CLASSES) * 3,\n",
    "    layer_dim=0,\n",
    "    ft_dim=64,\n",
    "    n_fts=45 + 75,\n",
    "    resize=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {k: fts[k].unsqueeze(0) for k in fts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = model(x)\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = StudyLoss()\n",
    "l(pred, y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsna_loss(y.unsqueeze(0).numpy(), pred.softmax(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "    targets = CLASSES\n",
    "\n",
    "    # Data\n",
    "    exp_folders = {\n",
    "        # \"nfn\": \"../logs/2024-08-05/27/\",  # NEEDS IMPROVEMENT\n",
    "        # \"scs\": \"../logs/2024-08-04/33/\",  # NEEDS IMPROVEMENT\n",
    "        # \"ss\": \"../logs/2024-08-06/17/\",  # NEEDS IMPROVEMENT\n",
    "\n",
    "        \"scs_crop\": \"../logs/2024-08-07/19/\",  # 15\n",
    "        \"nfn_crop\": \"../logs/2024-08-07/32/\",  # 30\n",
    "        \"scs_crop_coords\": \"../logs/2024-08-13/1/\",  # 15\n",
    "        \"nfn_crop_coords\": \"../logs/2024-08-13/8/\",  # 30\n",
    "\n",
    "        \"crop\": \"../logs/2024-08-22/11/\",  # 75\n",
    "        # \"crop_ax\": \"../logs/2024-08-26/4/\",  # 75  NEEDS IMPROVEMENT\n",
    "    }\n",
    "    n_fts = 75 + 45 + 45 # + 75\n",
    "    resize = 30\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "    name = \"baseline\"\n",
    "    dense_dim = 8192 # - 1024\n",
    "    layer_dim = 0\n",
    "    ft_dim = 0\n",
    "\n",
    "    p = 0.4\n",
    "    num_classes = len(CLASSES) * 3\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"study\",\n",
    "        \"weighted\": True,\n",
    "        \"use_any\": True,\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"study\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"val_bs\": 512,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"sched\": False,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_classes_aux\": num_classes_aux,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 1e-4,\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        \"weight_decay\": 1,\n",
    "    }\n",
    "\n",
    "    epochs = 15\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 20\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "\n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data_lvl2()\n",
    "\n",
    "if \"fold\" not in df.columns:\n",
    "    folds = pd.read_csv(Config.folds_file)\n",
    "    df = df.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds = k_fold(Config, df, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in range(3, 4):   \n",
    "#     print(f'\\n - Fold {fold + 1}') \n",
    "#     idx = df[df['fold'] == fold].index\n",
    "#     df_val = df.iloc[idx]\n",
    "#     preds_val = preds[idx]\n",
    "\n",
    "#     avg_loss, losses = rsna_loss(df_val[Config.targets].values, preds_val)\n",
    "\n",
    "#     for k, v in losses.items():\n",
    "#         print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "#     print(f'\\n -> CV Score : {avg_loss :.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss, losses = rsna_loss(df[Config.targets].values, preds)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "print(f'\\n -> CV Score : {avg_loss :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = []\n",
    "for i, c in enumerate(CLASSES):\n",
    "    auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "    print(f'{c} AUC: \\t {auc :.4f}')\n",
    "    aucs.append(auc)\n",
    "print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = preds.reshape(preds.shape[0], 5, 5, 3)\n",
    "p = p.transpose(0, 2, 1, 3)\n",
    "p = p.reshape(-1, 5, 3)\n",
    "\n",
    "y = df[Config.targets].values\n",
    "y = y.reshape(preds.shape[0], 5, 5)\n",
    "y = y.transpose(0, 2, 1)\n",
    "y = y.reshape(-1, 5)\n",
    "\n",
    "aucs = []\n",
    "for i, c in enumerate(CLASSES_CROP):\n",
    "    auc = disk_auc(y[:, i], p[:, i])\n",
    "    print(f'{c} AUC: \\t {auc :.4f}')\n",
    "    aucs.append(auc)\n",
    "print(f'\\n-> Avg AUC: \\t {np.mean(aucs) :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(LEVELS_):\n",
    "    print(c, disk_auc(y[:, i], p[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scs_loss\t: 0.299\n",
    "- nfn_loss\t: 0.500\n",
    "- ss_loss\t: 0.593\n",
    "- any_loss\t: 0.291\n",
    "\n",
    " -> CV Score : 0.4206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [5, 6, 7, 8, 9, 15, 16, 17, 18, 19]:\n",
    "    j = i + 5\n",
    "    c = CLASSES[i]\n",
    "    c2 = CLASSES[j]\n",
    "    \n",
    "    ref_auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "    auc = disk_auc(df[Config.targets].values[:, i], preds[:, j])\n",
    "    r = (\n",
    "        spearmanr(preds[:, i][:, 1], preds[:, j][:, 1]).statistic + \n",
    "        spearmanr(preds[:, i][:, 2], preds[:, j][:, 2]).statistic\n",
    "    ) / 2\n",
    "    print(f'\\npred: {c2} \\t truth: {c}')\n",
    "    # print(r)\n",
    "    y1 = df[Config.targets].values[:, i]\n",
    "    y2 = df[Config.targets].values[:, j]\n",
    "    \n",
    "    eq = (y1[(y1 > 0) & (y2 > 0)] == y2[(y1 > 0) & (y2 > 0)]).mean()\n",
    "    print(f'Ref AUC          : {ref_auc :.4f}')\n",
    "    print(f'Swap AUC         : {auc :.4f}')\n",
    "    print(f'Equal proportion : {eq:.3f}')\n",
    "    print(f'Preds correlation: {r:.3f}')\n",
    "\n",
    "\n",
    "for j in [5, 6, 7, 8, 9, 15, 16, 17, 18, 19]:\n",
    "    i = j + 5\n",
    "    c = CLASSES[i]\n",
    "    c2 = CLASSES[j]\n",
    "    \n",
    "    ref_auc = disk_auc(df[Config.targets].values[:, i], preds[:, i])\n",
    "    auc = disk_auc(df[Config.targets].values[:, i], preds[:, j])\n",
    "    r = (\n",
    "        spearmanr(preds[:, i][:, 1], preds[:, j][:, 1]).statistic + \n",
    "        spearmanr(preds[:, i][:, 2], preds[:, j][:, 2]).statistic\n",
    "    ) / 2\n",
    "    print(f'\\npred: {c2} \\t truth: {c}')\n",
    "    # print(r)\n",
    "    y1 = df[Config.targets].values[:, i]\n",
    "    y2 = df[Config.targets].values[:, j]\n",
    "    \n",
    "    eq = (y1[(y1 > 0) & (y2 > 0)] == y2[(y1 > 0) & (y2 > 0)]).mean()\n",
    "    print(f'Ref AUC          : {ref_auc :.4f}')\n",
    "    print(f'Swap AUC         : {auc :.4f}')\n",
    "    print(f'Equal proportion : {eq:.3f}')\n",
    "    print(f'Preds correlation: {r:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "y = df[Config.targets].values\n",
    "for i in tqdm(range(len(df))):\n",
    "    l = rsna_loss(y[i:i+1], preds[i:i+1])[1]\n",
    "    l.update({\"study\": df[\"study_id\"].values[i]})\n",
    "    losses.append(l)\n",
    "losses = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "for i, c in enumerate(losses.columns[:-1]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    sns.histplot(losses[c].values)\n",
    "    plt.title(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[losses[\"scs\"] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"study_id\"] == 1972129014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[losses[\"any\"] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scs_loss\t: 0.325\n",
    "- nfn_loss\t: 0.517\n",
    "- ss_loss\t: 0.634\n",
    "- any_loss\t: 0.297\n",
    "\n",
    " -> CV Score : 0.443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
