{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qqq /kaggle/input/rsna-abdomen-packages/{pydicom-2.4.3-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n",
    "# !pip install -qqq /kaggle/input/rsna-abdomen-packages/dicomsdl-0.109.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "# !pip install -qqq /kaggle/input/contrails-model-def1/einops-0.6.1-py3-none-any.whl\n",
    "# !pip install -qqq --no-index --find-links /kaggle/input/contrails-wheels/ pretrainedmodels==0.7.4\n",
    "# !pip install -qqq --no-index --find-links /kaggle/input/contrails-wheels/ efficientnet_pytorch==0.7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/kaggle/input/rsna-lumbar-spine-code/src\"):\n",
    "    !cp -r /kaggle/input/rsna-lumbar-spine-code/src ./\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from util.torch import load_model_weights\n",
    "from util.plots import plot_mask, add_rect\n",
    "from util.metrics import rsna_loss\n",
    "\n",
    "from data.processing import process_and_save\n",
    "from data.transforms import get_transfos\n",
    "from data.dataset import CropDataset, CoordsDataset\n",
    "from data.preparation import prepare_data_crop\n",
    "\n",
    "from inference.seg import get_crops\n",
    "from inference.dataset import ImageInfDataset, FeatureInfDataset, SafeDataset\n",
    "from inference.lvl1 import predict, Config\n",
    "\n",
    "if os.path.exists(\"/kaggle/input/timm-smp\"):\n",
    "    sys.path.append(\n",
    "        \"/kaggle/input/timm-smp/pytorch-image-models-main/pytorch-image-models-main\"\n",
    "    )\n",
    "    sys.path.append(\n",
    "        \"/kaggle/input/timm-smp/segmentation_models.pytorch-master/segmentation_models.pytorch-master\"\n",
    "    )\n",
    "from model_zoo.models import define_model\n",
    "from model_zoo.models_lvl2 import define_model as define_model_2\n",
    "from model_zoo.models_seg import define_model as define_model_seg\n",
    "from model_zoo.models_seg import convert_3d\n",
    "\n",
    "from params import CLASSES_SEG, MODES, LEVELS_, SEVERITIES, LEVELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install albumentations==1.4.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = True\n",
    "DEBUG = True\n",
    "\n",
    "ROOT_DATA_DIR = \"../input/\"\n",
    "DEBUG_DATA_DIR = \"../output/dataset_debug/\"  # Todo\n",
    "SAVE_FOLDER = \"../output/tmp/\"\n",
    "shutil.rmtree(SAVE_FOLDER)\n",
    "\n",
    "# ROOT_DATA_DIR = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "# DEBUG_DATA_DIR = \"/kaggle/input/rsna-2024-debug/\"\n",
    "# SAVE_FOLDER = \"/tmp/\"\n",
    "\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "os.makedirs(SAVE_FOLDER + \"npy/\", exist_ok=True)\n",
    "os.makedirs(SAVE_FOLDER + \"mid/\", exist_ok=True)\n",
    "os.makedirs(SAVE_FOLDER + \"csv/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = ROOT_DATA_DIR + \"test_images/\"\n",
    "folds_dict = {}\n",
    "\n",
    "if DEBUG:\n",
    "    df_meta = pd.read_csv(ROOT_DATA_DIR + \"train_series_descriptions.csv\")\n",
    "else:\n",
    "    df_meta = pd.read_csv(ROOT_DATA_DIR + \"test_series_descriptions.csv\")\n",
    "\n",
    "df_meta[\"weighting\"] = df_meta[\"series_description\"].apply(lambda x: x.split()[1][:2])\n",
    "df_meta[\"orient\"] = df_meta[\"series_description\"].apply(lambda x: x.split()[0])\n",
    "df_meta[\"study_series\"] = df_meta[\"study_id\"].astype(str) + \"_\" + df_meta[\"series_id\"].astype(str)\n",
    "\n",
    "if DEBUG:\n",
    "    if EVAL:\n",
    "        DATA_PATH = ROOT_DATA_DIR + \"train_images/\"\n",
    "        FOLDS_FILE = DEBUG_DATA_DIR + \"train_folded_v1.csv\"\n",
    "        folds = pd.read_csv(FOLDS_FILE)\n",
    "        df_meta = df_meta.merge(folds, how=\"left\")\n",
    "        df_meta = df_meta[df_meta['fold'] == 1].reset_index(drop=True)\n",
    "    else:\n",
    "        DATA_PATH = DEBUG_DATA_DIR + \"debug_images/\"\n",
    "        df_meta = df_meta.head(3)\n",
    "\n",
    "        # df_meta_ = df_meta.copy()\n",
    "        # df_meta_['study_id'] += 1\n",
    "        # df_meta_ = df_meta_[df_meta_['orient'] == \"Axial\"]\n",
    "        # df_meta = pd.concat([df_meta, df_meta_], ignore_index=True)\n",
    "        # df_meta[\"study_series\"] = df_meta[\"study_id\"].astype(str) + \"_\" + df_meta[\"series_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BATCH_SIZE_2 = 512\n",
    "USE_FP16 = True\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "FOLD = 1 if DEBUG else \"fullfit_0\"\n",
    "PLOT = DEBUG and not EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Level 2 model: ../logs/2024-09-14/0/\n",
      "crop ../logs/2024-09-13/7/ ../logs/2024-09-13/7/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXP_FOLDERS = {\n",
    "    # \"scs\": (\"../logs/2024-08-04/33/\", [FOLD]),\n",
    "    # \"nfn\": (\"../logs/2024-08-05/27/\", [FOLD]),\n",
    "    # \"ss\": (\"../logs/2024-08-06/17/\", [FOLD]),\n",
    "}\n",
    "\n",
    "COORDS_FOLDERS = {\n",
    "    \"sag\": (\"../output/2024-08-29_0/\", FOLD),\n",
    "    # \"ax\": (\"../logs/2024-09-02/33/\", FOLD),\n",
    "}\n",
    "\n",
    "CROP_EXP_FOLDERS = {\n",
    "    \"crop\": (\"../logs/2024-09-13/7/\", [FOLD], \"crops_0.1\"),\n",
    "}\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "    \"../logs/2024-09-14/0/\"\n",
    "]\n",
    "FOLDS_2 = [FOLD] if DEBUG else [0, 1, 2, 3]\n",
    "\n",
    "EXP_FOLDER_3D = \"../logs/2024-07-31/25/\"\n",
    "\n",
    "for f in EXP_FOLDERS_2:\n",
    "    folders = Config(json.load(open(f + \"config.json\", \"r\"))).exp_folders\n",
    "    print(\"-> Level 2 model:\", f)\n",
    "    for k in folders:\n",
    "        print(k, folders[k], EXP_FOLDERS.get(k, CROP_EXP_FOLDERS.get(k, [\"?\"]))[0])\n",
    "    print()\n",
    "\n",
    "    \n",
    "for k in EXP_FOLDERS:\n",
    "    assert os.path.exists(EXP_FOLDERS[k][0]), f\"Model not found: {k}\"\n",
    "for k in CROP_EXP_FOLDERS:\n",
    "    assert os.path.exists(CROP_EXP_FOLDERS[k][0]), f\"Crop model not found: {k}\"\n",
    "for k in COORDS_FOLDERS:\n",
    "    assert os.path.exists(COORDS_FOLDERS[k][0]), f\"Coords model not found: {k}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>weighting</th>\n",
       "      <th>orient</th>\n",
       "      <th>study_series</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "      <td>T2</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>4003253_702807833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>4003253_1054713880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>Axial T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>Axial</td>\n",
       "      <td>4003253_2448190387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>481125819</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "      <td>T2</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>8785691_481125819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8785691</td>\n",
       "      <td>1570286759</td>\n",
       "      <td>Sagittal T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>8785691_1570286759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id series_description weighting    orient  \\\n",
       "0   4003253   702807833   Sagittal T2/STIR        T2  Sagittal   \n",
       "1   4003253  1054713880        Sagittal T1        T1  Sagittal   \n",
       "2   4003253  2448190387           Axial T2        T2     Axial   \n",
       "3   8785691   481125819   Sagittal T2/STIR        T2  Sagittal   \n",
       "4   8785691  1570286759        Sagittal T1        T1  Sagittal   \n",
       "\n",
       "         study_series  fold  \n",
       "0   4003253_702807833     1  \n",
       "1  4003253_1054713880     1  \n",
       "2  4003253_2448190387     1  \n",
       "3   8785691_481125819     1  \n",
       "4  8785691_1570286759     1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Copying ../logs/2024-09-13/7/ ...\n",
      "- Copying ../logs/2024-09-14/0/ ...\n",
      "\n",
      "Dataset size : 0.857 Go\n",
      "- Update existing dataset !\n",
      "- Uploading ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22.0/22.0 [00:00<00:00, 53.8B/s]\n",
      "100%|██████████| 2.93M/2.93M [00:00<00:00, 7.00MB/s]\n",
      "100%|██████████| 807M/807M [00:04<00:00, 186MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output :\n",
      " b'Starting upload for file .ipynb_checkpoints.zip\\nUpload successful: .ipynb_checkpoints.zip (22B)\\nStarting upload for file 2024-09-14_0.zip\\nUpload successful: 2024-09-14_0.zip (3MB)\\nStarting upload for file 2024-09-13_7.zip\\nUpload successful: 2024-09-13_7.zip (807MB)\\nDataset version is being created. Please check progress at https://www.kaggle.com/theoviel/rsna-2024-weights-2\\n'\n",
      "\n",
      "Error :\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "from util.logger import upload_to_kaggle\n",
    "\n",
    "folders = [EXP_FOLDERS[k][0] for k in EXP_FOLDERS]\n",
    "folders += [CROP_EXP_FOLDERS[k][0] for k in CROP_EXP_FOLDERS]\n",
    "# folders += [COORDS_FOLDERS[k][0] for k in COORDS_FOLDERS]\n",
    "folders += EXP_FOLDERS_2 # + [EXP_FOLDER_3D]\n",
    "folders = list(set(folders))\n",
    "\n",
    "upload_to_kaggle(folders, \"../output/dataset_2/\", \"RSNA 2024 Weights 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adb6fa490224501a0b7e73425df8fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1587 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = Parallel(n_jobs=NUM_WORKERS)(\n",
    "    delayed(process_and_save)(\n",
    "        df_meta['study_id'][i],\n",
    "        df_meta['series_id'][i],\n",
    "        df_meta['orient'][i],\n",
    "        DATA_PATH,\n",
    "        save_folder=SAVE_FOLDER,\n",
    "        save_meta=False,\n",
    "        save_middle_frame=True,\n",
    "    ) for i in tqdm(range(len(df_meta)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG and not EVAL:\n",
    "#     from data.preparation import prepare_data_crop\n",
    "\n",
    "#     ref_folder = DEBUG_DATA_DIR + \"npy/\"\n",
    "#     # png_ref_folder = \"../input/coords/comp_data/\"\n",
    "\n",
    "#     for i in range(len(df_meta)):\n",
    "#         study_series = df_meta[\"study_series\"][i]\n",
    "#         npy_ref = np.load(ref_folder + f\"{study_series}.npy\")\n",
    "#         npy = np.load(SAVE_FOLDER + f\"npy/{study_series}.npy\")\n",
    "#         assert (npy == npy_ref).all()\n",
    "\n",
    "#         # if df_meta['orient'][i] == \"Axial\":\n",
    "#         #     continue\n",
    "\n",
    "#         # png_ref = cv2.imread(png_ref_folder + f\"{study_series}.png\")\n",
    "#         # png = cv2.imread(SAVE_FOLDER + f\"mid/{study_series}.png\")\n",
    "\n",
    "#         # # plt.subplot(1, 2, 1)\n",
    "#         # # plt.imshow(png, cmap=\"gray\")\n",
    "#         # # plt.subplot(1, 2, 2)\n",
    "#         # # plt.imshow(png_ref, cmap=\"gray\")\n",
    "#         # # plt.show()\n",
    "        \n",
    "#         # assert (png == png_ref).all()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagittal Coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>weighting</th>\n",
       "      <th>orient</th>\n",
       "      <th>study_series</th>\n",
       "      <th>img_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "      <td>T2</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>4003253_702807833</td>\n",
       "      <td>../output/tmp/mid/4003253_702807833.png</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>4003253_1054713880</td>\n",
       "      <td>../output/tmp/mid/4003253_1054713880.png</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8785691</td>\n",
       "      <td>481125819</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "      <td>T2</td>\n",
       "      <td>Sagittal</td>\n",
       "      <td>8785691_481125819</td>\n",
       "      <td>../output/tmp/mid/8785691_481125819.png</td>\n",
       "      <td>[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id series_description weighting    orient  \\\n",
       "0   4003253   702807833   Sagittal T2/STIR        T2  Sagittal   \n",
       "1   4003253  1054713880        Sagittal T1        T1  Sagittal   \n",
       "2   8785691   481125819   Sagittal T2/STIR        T2  Sagittal   \n",
       "\n",
       "         study_series                                  img_path  \\\n",
       "0   4003253_702807833   ../output/tmp/mid/4003253_702807833.png   \n",
       "1  4003253_1054713880  ../output/tmp/mid/4003253_1054713880.png   \n",
       "2   8785691_481125819   ../output/tmp/mid/8785691_481125819.png   \n",
       "\n",
       "                                              target  \n",
       "0  [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...  \n",
       "1  [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...  \n",
       "2  [[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sag = df_meta[df_meta[\"orient\"] == \"Sagittal\"].reset_index(drop=True)\n",
    "df_sag = df_sag[df_sag.columns[:6]]\n",
    "\n",
    "df_sag['img_path'] = SAVE_FOLDER + \"mid/\" + df_sag[\"study_series\"] + \".png\"\n",
    "df_sag['target'] = [np.ones((5, 2)) for _ in range(len(df_sag))]\n",
    "\n",
    "df_sag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src/util/torch.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../output/2024-08-29_0/coatnet_rmlp_2_rw_384_1.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_sag = Config(json.load(open(COORDS_FOLDERS['sag'][0] + \"config.json\", \"r\")))\n",
    "\n",
    "model_sag = define_model(\n",
    "    config_sag.name,\n",
    "    drop_rate=config_sag.drop_rate,\n",
    "    drop_path_rate=config_sag.drop_path_rate,\n",
    "    pooling=config_sag.pooling,\n",
    "    num_classes=config_sag.num_classes,\n",
    "    num_classes_aux=config_sag.num_classes_aux,\n",
    "    n_channels=config_sag.n_channels,\n",
    "    reduce_stride=config_sag.reduce_stride,\n",
    "    pretrained=False,\n",
    ")\n",
    "model_sag = model_sag.cuda().eval()\n",
    "\n",
    "weights = COORDS_FOLDERS['sag'][0] + f\"{config_sag.name}_{COORDS_FOLDERS['sag'][1]}.pt\"\n",
    "model_sag = load_model_weights(model_sag, weights, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src/inference/lvl1.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_fp16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.99 s, sys: 920 ms, total: 7.91 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transfos = get_transfos(augment=False, resize=config_sag.resize, use_keypoints=True)\n",
    "dataset = CoordsDataset(df_sag, transforms=transfos)\n",
    "dataset = SafeDataset(dataset)\n",
    "\n",
    "preds_sag, _ = predict(model_sag, dataset, config_sag.loss_config, batch_size=32, use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTAS = [0.1]  #, 0.15]\n",
    "\n",
    "for delta in DELTAS:\n",
    "    os.makedirs(SAVE_FOLDER + f\"crops_{delta}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aeb04b6c2f4966ba1241d2ff758fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/989 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in tqdm(range(len(df_sag))):\n",
    "    study_series = df_sag[\"study_series\"][idx]\n",
    "    imgs_path = SAVE_FOLDER + \"npy/\" + study_series + \".npy\"\n",
    "\n",
    "    imgs = np.load(imgs_path)\n",
    "\n",
    "    preds = preds_sag[idx].reshape(-1, 2).copy()\n",
    "\n",
    "    for delta in DELTAS:  # , 0.15\n",
    "        crops = np.concatenate([preds, preds], -1)\n",
    "        crops[:, [0, 1]] -= delta\n",
    "        crops[:, [2, 3]] += delta\n",
    "        crops = crops.clip(0, 1)\n",
    "\n",
    "        crops[:, [0, 2]] *= imgs.shape[2]\n",
    "        crops[:, [1, 3]] *= imgs.shape[1]\n",
    "        crops = crops.astype(int)\n",
    "\n",
    "        img_crops = []\n",
    "        for i, (x0, y0, x1, y1) in enumerate(crops):\n",
    "\n",
    "            crop = imgs[:, y0: y1, x0: x1].copy()\n",
    "            # crop = np.zeros((3, 1, 1))\n",
    "            try:\n",
    "                assert crop.shape[2] >= 1 and crop.shape[1] >= 1\n",
    "            except AssertionError:\n",
    "                # print('!!')\n",
    "                # pass\n",
    "                crop = imgs.copy()\n",
    "\n",
    "            np.save(SAVE_FOLDER + f\"crops_{delta}/{study_series}_{LEVELS_[i]}.npy\", crop)\n",
    "            img_crops.append(crop[len(crop) // 2])\n",
    "\n",
    "        if PLOT:\n",
    "            preds[:, 0] *= imgs.shape[2]\n",
    "            preds[:, 1] *= imgs.shape[1]\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(imgs[len(imgs) // 2], cmap=\"gray\")\n",
    "            plt.scatter(preds[:, 0], preds[:, 1], marker=\"x\", label=\"center\")\n",
    "            plt.title(study_series)\n",
    "            plt.axis(False)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            for i in range(5):\n",
    "                plt.subplot(1, 5, i + 1)\n",
    "                plt.imshow(img_crops[i], cmap=\"gray\")\n",
    "                plt.axis(False)\n",
    "                plt.title(LEVELS[i])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and not EVAL:\n",
    "    ref_folder = DEBUG_DATA_DIR + \"coords_crops_0.1/\"\n",
    "    df_ref = prepare_data_crop(ROOT_DATA_DIR, ref_folder).head(10)\n",
    "\n",
    "    df_ref['img_path_2'] = df_ref['img_path'].apply(\n",
    "        lambda x: re.sub(ref_folder, SAVE_FOLDER + f\"crops_0.1/\", x)\n",
    "    )\n",
    "\n",
    "    for i in range(len(df_ref)):\n",
    "        cref = np.load(df_ref['img_path'][i])\n",
    "        c = np.load(df_ref['img_path_2'][i])\n",
    "        assert (cref == c).all()\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.imshow(c[len(c) // 2], cmap=\"gray\")\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.imshow(cref[len(cref) // 2], cmap=\"gray\")\n",
    "        # plt.show()\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axial Coords\n",
    "- Not used yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seg & Level 1\n",
    "- Not used currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_seg = Config(json.load(open(EXP_FOLDER_3D + \"config.json\", \"r\")))\n",
    "\n",
    "# model_seg = define_model_seg(\n",
    "#     config_seg.decoder_name,\n",
    "#     config_seg.name,\n",
    "#     num_classes=config_seg.num_classes,\n",
    "#     num_classes_aux=config_seg.num_classes_aux,\n",
    "#     increase_stride=config_seg.increase_stride,\n",
    "#     use_cls=config_seg.use_cls,\n",
    "#     n_channels=config_seg.n_channels,\n",
    "#     use_3d=config_seg.use_3d,\n",
    "#     pretrained=False,\n",
    "# )\n",
    "\n",
    "# model_seg = load_model_weights(\n",
    "#     model_seg, EXP_FOLDER_3D + f\"{config_seg.name}_{FOLD}.pt\"\n",
    "# )\n",
    "# model_seg = model_seg.cuda()\n",
    "# # model_seg = model_seg.eval()  # Hurts results ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {}\n",
    "# for mode in EXP_FOLDERS:\n",
    "#     exp_folder, folds = EXP_FOLDERS[mode]\n",
    "#     print(f\"- Mode: {mode}\")\n",
    "#     config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "#     models_ = []\n",
    "#     for fold in folds:\n",
    "#         model = define_model(\n",
    "#             config.name,\n",
    "#             drop_rate=config.drop_rate,\n",
    "#             drop_path_rate=config.drop_path_rate,\n",
    "#             use_gem=config.use_gem,\n",
    "#             num_classes=config.num_classes,\n",
    "#             num_classes_aux=config.num_classes_aux,\n",
    "#             n_channels=config.n_channels,\n",
    "#             reduce_stride=config.reduce_stride,\n",
    "#             increase_stride=(\n",
    "#                 config.increase_stride if hasattr(config, \"increase_stride\") else False\n",
    "#             ),\n",
    "#             pretrained=False,\n",
    "#         )\n",
    "#         model = model.cuda().eval()\n",
    "\n",
    "#         weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "#         model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "#         models_.append(model)\n",
    "\n",
    "#     models[mode] = models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# for study in tqdm(sorted(os.listdir(DATA_PATH))):\n",
    "#     if folds_dict.get(int(study), 0) != FOLD and EVAL:\n",
    "#         continue\n",
    "\n",
    "#     for series in sorted(os.listdir(DATA_PATH + study)):\n",
    "#         print(\"\\n-> study\", study, \"- Series\", series)\n",
    "\n",
    "#         imgs, orient, weighting = process(\n",
    "#             study,\n",
    "#             series,\n",
    "#             data_path=DATA_PATH,\n",
    "#             on_gpu=False,\n",
    "#         )\n",
    "\n",
    "#         try:\n",
    "#             weighting, orient = df_meta.loc[(int(study), int(series))].values[1:]\n",
    "#             # print(orient, weighting)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         dfs.append(\n",
    "#             {\n",
    "#                 \"study_id\": study,\n",
    "#                 \"series_id\": series,\n",
    "#                 \"orient\": orient,\n",
    "#                 \"weighting\": weighting,\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#         print(f\"- Orient {orient} - Weighting {weighting}\")\n",
    "\n",
    "#         # Segmentation\n",
    "#         if orient == \"Sagittal\":\n",
    "#             x = imgs[:, ::-1].copy().astype(np.float32)\n",
    "\n",
    "#             with torch.inference_mode():\n",
    "#                 x = torch.from_numpy(x).cuda()\n",
    "#                 x = F.interpolate(\n",
    "#                     x.unsqueeze(0).unsqueeze(0),\n",
    "#                     config_seg.img_size,\n",
    "#                     mode=\"trilinear\",\n",
    "#                 )\n",
    "#                 x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "#                 mask, _ = model_seg(x)\n",
    "#                 mask = F.interpolate(\n",
    "#                     mask,\n",
    "#                     imgs.shape,\n",
    "#                     mode=\"trilinear\",\n",
    "#                 )[\n",
    "#                     0\n",
    "#                 ].argmax(0)\n",
    "#             mask = mask.cpu().numpy()[:, ::-1].astype(np.uint8)\n",
    "\n",
    "#             if DEBUG and PLOT:\n",
    "#                 img_ref = np.load(DEBUG_DATA_DIR + f\"npy/{study}_{series}.npy\")\n",
    "#                 mask_ref = np.load(DEBUG_DATA_DIR + f\"train_segs/{study}_{series}.npy\")\n",
    "#                 delta = (np.abs(mask - mask_ref) > 0).mean()\n",
    "#                 print(\"Mask delta:\", delta)\n",
    "#                 delta = (np.abs(imgs - img_ref) > 0).mean()\n",
    "#                 print(\"Img delta:\", delta)\n",
    "\n",
    "#             if PLOT:\n",
    "#                 f = len(imgs) // 2\n",
    "#                 plt.figure(figsize=(4, 4))\n",
    "#                 plot_mask(imgs[f], mask[f])\n",
    "#                 plt.show()\n",
    "\n",
    "#             # Cropping\n",
    "#             disk_crops = {}\n",
    "#             for disk in CLASSES_SEG[5:]:\n",
    "#                 x0, x1, y0, y1, z0, z1 = get_crops(mask, disk=disk)\n",
    "#                 disk_crops[disk] = (x0, x1, y0, y1, z0, z1)\n",
    "\n",
    "#                 img_crop = imgs[x0:x1, y0:y1, z0:z1]\n",
    "#                 # mask_crop = mask[x0: x1, y0:y1, z0:z1]\n",
    "\n",
    "#                 d = re.sub(\"/\", \"_\", disk.lower())\n",
    "#                 np.save(SAVE_FOLDER + f\"{study}_{series}_{d}.npy\", img_crop.copy())\n",
    "\n",
    "#             if PLOT:\n",
    "#                 plt.figure(figsize=(8, 8))\n",
    "#                 plot_mask(imgs[f], mask[f])\n",
    "\n",
    "#                 for d, disk in enumerate(disk_crops):\n",
    "#                     x0, x1, y0, y1, z0, z1 = disk_crops[disk]\n",
    "#                     add_rect(x0, x1, y0, y1, z0, z1, f, col=\"skyblue\")\n",
    "#                     plt.text(\n",
    "#                         10,\n",
    "#                         (d + 1) * 20,\n",
    "#                         f\"{disk} disk center frame: {int((x1 + x0) / 2)}\",\n",
    "#                         color=\"skyblue\",\n",
    "#                     )\n",
    "#                 plt.show()\n",
    "\n",
    "#         # Cls\n",
    "#         mode = MODES[weighting + \"_\" + orient]\n",
    "#         exp_folder, models_list = EXP_FOLDERS[mode][0], models[mode]\n",
    "\n",
    "#         config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "#         imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min()) * 255\n",
    "#         imgs = imgs.astype(np.uint8)\n",
    "\n",
    "#         transforms = get_transfos(augment=False, resize=config.resize, crop=config.crop)\n",
    "#         dataset = ImageInfDataset(\n",
    "#             imgs,\n",
    "#             transforms=transforms,\n",
    "#             frames_chanel=(\n",
    "#                 config.frames_chanel if hasattr(config, \"frames_chanel\") else 0\n",
    "#             ),\n",
    "#             n_frames=config.n_frames if hasattr(config, \"n_frames\") else 1,\n",
    "#             stride=config.stride if hasattr(config, \"stride\") else 1,\n",
    "#         )\n",
    "\n",
    "#         preds = []\n",
    "#         for model in models_list:\n",
    "#             pred, pred_aux = predict(\n",
    "#                 model,\n",
    "#                 dataset,\n",
    "#                 config.loss_config,\n",
    "#                 batch_size=BATCH_SIZE,\n",
    "#                 use_fp16=USE_FP16,\n",
    "#                 num_workers=NUM_WORKERS,\n",
    "#             )\n",
    "#             preds.append(pred)\n",
    "#         preds = np.mean(preds, 0)\n",
    "\n",
    "#         if PLOT:\n",
    "#             plt.figure(figsize=(8, 5))\n",
    "#             plt.plot(preds[:, :, 0])\n",
    "#             plt.show()\n",
    "\n",
    "#         np.save(SAVE_FOLDER + f\"{study}_{series}_{mode}.npy\", preds)\n",
    "\n",
    "# del model_seg, models, imgs, x, mask, dataset\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG and not EVAL:\n",
    "#     for study in sorted(os.listdir(DATA_PATH)):\n",
    "#         for series in sorted(os.listdir(DATA_PATH + study)):\n",
    "#             print(\"-> study\", study, \"- Series\", series)\n",
    "#             for mode in EXP_FOLDERS:\n",
    "#                 exp_folder, folds = EXP_FOLDERS[mode]\n",
    "#                 try:\n",
    "#                     preds_ref = np.load(exp_folder + f\"preds/{study}_{series}.npy\")\n",
    "#                 except:\n",
    "#                     continue\n",
    "\n",
    "#                 preds = np.load(SAVE_FOLDER + f\"{study}_{series}_{mode}.npy\")\n",
    "\n",
    "#                 assert preds.shape == preds_ref.shape\n",
    "\n",
    "#                 delta = ((preds - preds_ref) ** 2).max()\n",
    "#                 print(f\"{mode} delta :\", delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG and not EVAL:\n",
    "#     df[\"img_path_ref\"] = DEBUG_DATA_DIR + \"crops_fix/\"\n",
    "#     df[\"img_path_ref\"] += (\n",
    "#         df[\"study_id\"] + \"_\" + df[\"series_id\"] + \"_\" + df[\"level\"] + \".npy\"\n",
    "#     )\n",
    "#     for i in range(len(df)):\n",
    "#         path_ref = df[\"img_path_ref\"][i]\n",
    "#         path = df[\"img_path\"][i]\n",
    "\n",
    "#         if os.path.exists(path_ref):\n",
    "#             crop_ref = np.load(path_ref)\n",
    "#             crop = np.load(path)\n",
    "\n",
    "#             print(\n",
    "#                 f\"Crop {path.split('/')[-1][:-4]} delta:\\t\",\n",
    "#                 ((crop_ref - crop) ** 2).max(),\n",
    "#             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_meta.copy()\n",
    "\n",
    "df[\"target\"] = 0\n",
    "df[\"coords\"] = 0\n",
    "\n",
    "df[\"level\"] = [LEVELS for _ in range(len(df))]\n",
    "df[\"level_\"] = [LEVELS_ for _ in range(len(df))]\n",
    "df = df.explode([\"level\", \"level_\"]).reset_index(drop=True)\n",
    "df[\"img_path_\"] = df[\"study_series\"] + \"_\" + df[\"level_\"] + \".npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b414adb40ba4f3082269c4b47199608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Model crop - ../logs/2024-09-13/7/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src/util/torch.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2024-09-13/7/coatnet_1_rw_224_1.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src/inference/lvl1.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_fp16):\n"
     ]
    }
   ],
   "source": [
    "crop_fts = {}\n",
    "for mode in tqdm(CROP_EXP_FOLDERS, total=len(CROP_EXP_FOLDERS)):\n",
    "    exp_folder, folds, crop_folder = CROP_EXP_FOLDERS[mode]\n",
    "    print(f\"- Model {mode} - {exp_folder}\")\n",
    "\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    if mode == \"crop\":\n",
    "        df_mode = df[df['orient'] == \"Sagittal\"].reset_index(drop=True)\n",
    "        df_mode[\"side\"] = \"Center\"\n",
    "    elif \"scs\" in mode:\n",
    "        df_mode = df[df['orient'] == \"Sagittal\"]\n",
    "        df_mode = df_mode[df_mode[\"weighting\"] == \"T2\"].reset_index(drop=True)\n",
    "        df_mode[\"side\"] = \"Center\"\n",
    "    elif \"nfn\" in mode:\n",
    "        df_mode = df[df['orient'] == \"Sagittal\"]\n",
    "        df_mode[\"side\"] = [\"Right\", \"Left\"]\n",
    "        df_mode = df_mode.explode(\"side\").reset_index(drop=True)\n",
    "        df_mode = df_mode.sort_values(\n",
    "            [\"study_id\", \"series_id\", \"side\", \"level\"],\n",
    "            ascending=[True, True, False, True],\n",
    "            ignore_index=True\n",
    "        )\n",
    "    elif \"ss\" in mode:\n",
    "        df_mode = df[df['orient'] == \"Axial\"]\n",
    "        df_mode[\"side\"] = [\"Right\", \"Left\"]\n",
    "        df_mode = df_mode.explode(\"side\").reset_index(drop=True)\n",
    "        df_mode = df_mode.sort_values(\n",
    "            [\"study_id\", \"series_id\", \"side\", \"level\"],\n",
    "            ascending=[True, True, False, True],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    df_mode['img_path'] = SAVE_FOLDER + crop_folder + \"/\" + df_mode[\"img_path_\"]\n",
    "\n",
    "    transfos = get_transfos(augment=False, resize=config.resize, crop=config.crop)\n",
    "    dataset = CropDataset(\n",
    "        df_mode,\n",
    "        targets=\"target\",\n",
    "        transforms=transfos,\n",
    "        frames_chanel=config.frames_chanel,\n",
    "        n_frames=config.n_frames,\n",
    "        stride=config.stride,\n",
    "        train=False,\n",
    "        load_in_ram=False,\n",
    "    )\n",
    "    dataset = SafeDataset(dataset)\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        pooling=config.pooling,\n",
    "        head_3d=config.head_3d,\n",
    "        n_frames=config.n_frames,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        pretrained=False,\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "\n",
    "    preds = []\n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=1)\n",
    "\n",
    "        pred, _ = predict(\n",
    "            model,\n",
    "            dataset,\n",
    "            config.loss_config,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.mean(preds, 0)\n",
    "\n",
    "    if PLOT:\n",
    "        df_ref = pd.read_csv(exp_folder + f\"df_val_{FOLD}.csv\").head(len(preds))\n",
    "        # order_ref = df_ref.sort_values([\"side\", \"level\"]).index.values\n",
    "        preds_ref = np.load(exp_folder + f\"pred_inf_{FOLD}.npy\")[: len(preds)]  # [order_ref]\n",
    "\n",
    "        # plt.figure(figsize=(8, 4))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.plot(preds)\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.plot(preds_ref)\n",
    "        # plt.show()\n",
    "\n",
    "        delta = (np.abs(preds - preds_ref)).max()\n",
    "        print(preds.shape, preds_ref.shape)\n",
    "        print(f\"{mode} delta:\", delta)\n",
    "\n",
    "    idx = df_mode[[\"study_id\", \"series_id\", \"level\", \"side\"]].values.astype(str).tolist()\n",
    "    idx = [\"_\".join(i) for i in idx]\n",
    "    crop_fts[mode] = dict(zip(idx, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_to_dict(file):\n",
    "    sub = pd.read_csv(file)\n",
    "    sub['study'] = sub['row_id'].apply(lambda x: x.split('_')[0])\n",
    "    sub['tgt'] = sub['row_id'].apply(lambda x: x.split('_', 1)[-1])\n",
    "\n",
    "    cols = [\n",
    "        \"spinal_canal_stenosis_l1_l2\",\n",
    "        \"spinal_canal_stenosis_l2_l3\",\n",
    "        \"spinal_canal_stenosis_l3_l4\",\n",
    "        \"spinal_canal_stenosis_l4_l5\",\n",
    "        \"spinal_canal_stenosis_l5_s1\",\n",
    "        \"left_neural_foraminal_narrowing_l1_l2\",\n",
    "        \"left_neural_foraminal_narrowing_l2_l3\",\n",
    "        \"left_neural_foraminal_narrowing_l3_l4\",\n",
    "        \"left_neural_foraminal_narrowing_l4_l5\",\n",
    "        \"left_neural_foraminal_narrowing_l5_s1\",\n",
    "        \"right_neural_foraminal_narrowing_l1_l2\",\n",
    "        \"right_neural_foraminal_narrowing_l2_l3\",\n",
    "        \"right_neural_foraminal_narrowing_l3_l4\",\n",
    "        \"right_neural_foraminal_narrowing_l4_l5\",\n",
    "        \"right_neural_foraminal_narrowing_l5_s1\",\n",
    "        \"left_subarticular_stenosis_l1_l2\",\n",
    "        \"left_subarticular_stenosis_l2_l3\",\n",
    "        \"left_subarticular_stenosis_l3_l4\",\n",
    "        \"left_subarticular_stenosis_l4_l5\",\n",
    "        \"left_subarticular_stenosis_l5_s1\",\n",
    "        \"right_subarticular_stenosis_l1_l2\",\n",
    "        \"right_subarticular_stenosis_l2_l3\",\n",
    "        \"right_subarticular_stenosis_l3_l4\",\n",
    "        \"right_subarticular_stenosis_l4_l5\",\n",
    "        \"right_subarticular_stenosis_l5_s1\",\n",
    "    ]\n",
    "\n",
    "    preds_dict = {}\n",
    "    for study, dfs in sub.groupby('study'):\n",
    "        # display(dfs)\n",
    "        dfs = dfs[[\"tgt\", \"normal_mild\", \"moderate\", \"severe\"]].set_index(\"tgt\")\n",
    "        preds = np.zeros((25, 3))\n",
    "        for i, c in enumerate(cols):\n",
    "            preds[i] = dfs.loc[c].values\n",
    "        preds_dict[study] = preds\n",
    "    return preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_fts = {\n",
    "#     \"ch\": sub_to_dict(\"submission.csv\"),\n",
    "#     \"dh\": sub_to_dict(\"submission.csv\"),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_fts = {}\n",
    "# for k in ['ch', 'dh']:\n",
    "#     # config_2.exp_folders['dh'], config_2.exp_folders['ch']\n",
    "#     file = torch.load(config_2.exp_folders[k])\n",
    "#     csv_fts[k] = dict(zip(\n",
    "#         file[\"study_id\"].tolist(),\n",
    "#         file['logits'].float().cpu().numpy(),\n",
    "#     ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2024-09-14/0/simple_1.pt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_lumbar_spine/src/util/torch.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\")\n",
      "/workspace/kaggle_rsna_lumbar_spine/src/inference/lvl1.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_fp16):\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_meta[\n",
    "    [\"study_id\", \"series_id\", \"series_description\"]\n",
    "].groupby('study_id').agg(list).reset_index()\n",
    "\n",
    "all_preds = []\n",
    "for exp_folder in EXP_FOLDERS_2:\n",
    "    config_2 = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    csv_fts = {}\n",
    "    # for k in config_2.exp_folders:\n",
    "    #     if \"ch\" in k or \"dh\" in k:\n",
    "    #         file = torch.load(config_2.exp_folders[k])\n",
    "    #         csv_fts[k] = dict(zip(\n",
    "    #             file[\"study_id\"].tolist(),\n",
    "    #             file['logits'].float().cpu().numpy(),\n",
    "    #         ))\n",
    "\n",
    "\n",
    "    dataset = FeatureInfDataset(\n",
    "        df_2,\n",
    "        config_2.exp_folders,\n",
    "        crop_fts,\n",
    "        csv_fts,\n",
    "        save_folder=SAVE_FOLDER,\n",
    "    )\n",
    "    # dataset = SafeDataset(dataset)\n",
    "\n",
    "    model = define_model_2(\n",
    "        config_2.name,\n",
    "        ft_dim=config_2.ft_dim,\n",
    "        layer_dim=config_2.layer_dim,\n",
    "        dense_dim=config_2.dense_dim,\n",
    "        p=config_2.p,\n",
    "        n_fts=config_2.n_fts,\n",
    "        resize=config_2.resize,\n",
    "        num_classes=config_2.num_classes,\n",
    "        num_classes_aux=config_2.num_classes_aux,\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "\n",
    "    for fold in FOLDS_2:\n",
    "        weights = exp_folder + f\"{config_2.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "\n",
    "        preds, _ = predict(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_2.loss_config,\n",
    "            batch_size=BATCH_SIZE_2,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "        if DEBUG and not EVAL:\n",
    "            preds_ref = np.load(EXP_FOLDERS_2[0] + f\"pred_val_{fold}.npy\")[:1]\n",
    "            delta = np.abs(preds - preds_ref).max()\n",
    "            print(f\"Model {exp_folder} delta:\", delta)\n",
    "\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>4287160193_spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>4287160193_spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>0.905686</td>\n",
       "      <td>0.089195</td>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>4287160193_spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>0.991244</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>4287160193_spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>4287160193_spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>0.996024</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12330</th>\n",
       "      <td>4287160193_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.981638</td>\n",
       "      <td>0.017670</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12331</th>\n",
       "      <td>4287160193_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.505103</td>\n",
       "      <td>0.481502</td>\n",
       "      <td>0.013395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12332</th>\n",
       "      <td>4287160193_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.565046</td>\n",
       "      <td>0.424442</td>\n",
       "      <td>0.010512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12333</th>\n",
       "      <td>4287160193_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.663440</td>\n",
       "      <td>0.323651</td>\n",
       "      <td>0.012910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12334</th>\n",
       "      <td>4287160193_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.929238</td>\n",
       "      <td>0.066542</td>\n",
       "      <td>0.004220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12335</th>\n",
       "      <td>4287160193_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.939226</td>\n",
       "      <td>0.058910</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>4287160193_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.885808</td>\n",
       "      <td>0.111197</td>\n",
       "      <td>0.002995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>4287160193_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.348337</td>\n",
       "      <td>0.635083</td>\n",
       "      <td>0.016581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>4287160193_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.468930</td>\n",
       "      <td>0.513011</td>\n",
       "      <td>0.018059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>4287160193_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.951148</td>\n",
       "      <td>0.045374</td>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>4287160193_left_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.975287</td>\n",
       "      <td>0.021780</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12341</th>\n",
       "      <td>4287160193_left_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.141270</td>\n",
       "      <td>0.607388</td>\n",
       "      <td>0.251342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12342</th>\n",
       "      <td>4287160193_left_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.670156</td>\n",
       "      <td>0.304879</td>\n",
       "      <td>0.024965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12343</th>\n",
       "      <td>4287160193_left_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.753572</td>\n",
       "      <td>0.227746</td>\n",
       "      <td>0.018682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12344</th>\n",
       "      <td>4287160193_left_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.963151</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.005124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12345</th>\n",
       "      <td>4287160193_right_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.852462</td>\n",
       "      <td>0.137338</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12346</th>\n",
       "      <td>4287160193_right_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.762293</td>\n",
       "      <td>0.223498</td>\n",
       "      <td>0.014209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>4287160193_right_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.368856</td>\n",
       "      <td>0.539441</td>\n",
       "      <td>0.091703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>4287160193_right_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.686898</td>\n",
       "      <td>0.285190</td>\n",
       "      <td>0.027912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349</th>\n",
       "      <td>4287160193_right_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.959792</td>\n",
       "      <td>0.035685</td>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  row_id  normal_mild  \\\n",
       "12325             4287160193_spinal_canal_stenosis_l1_l2     0.996226   \n",
       "12326             4287160193_spinal_canal_stenosis_l2_l3     0.905686   \n",
       "12327             4287160193_spinal_canal_stenosis_l3_l4     0.991244   \n",
       "12328             4287160193_spinal_canal_stenosis_l4_l5     0.994419   \n",
       "12329             4287160193_spinal_canal_stenosis_l5_s1     0.996024   \n",
       "12330   4287160193_left_neural_foraminal_narrowing_l1_l2     0.981638   \n",
       "12331   4287160193_left_neural_foraminal_narrowing_l2_l3     0.505103   \n",
       "12332   4287160193_left_neural_foraminal_narrowing_l3_l4     0.565046   \n",
       "12333   4287160193_left_neural_foraminal_narrowing_l4_l5     0.663440   \n",
       "12334   4287160193_left_neural_foraminal_narrowing_l5_s1     0.929238   \n",
       "12335  4287160193_right_neural_foraminal_narrowing_l1_l2     0.939226   \n",
       "12336  4287160193_right_neural_foraminal_narrowing_l2_l3     0.885808   \n",
       "12337  4287160193_right_neural_foraminal_narrowing_l3_l4     0.348337   \n",
       "12338  4287160193_right_neural_foraminal_narrowing_l4_l5     0.468930   \n",
       "12339  4287160193_right_neural_foraminal_narrowing_l5_s1     0.951148   \n",
       "12340        4287160193_left_subarticular_stenosis_l1_l2     0.975287   \n",
       "12341        4287160193_left_subarticular_stenosis_l2_l3     0.141270   \n",
       "12342        4287160193_left_subarticular_stenosis_l3_l4     0.670156   \n",
       "12343        4287160193_left_subarticular_stenosis_l4_l5     0.753572   \n",
       "12344        4287160193_left_subarticular_stenosis_l5_s1     0.963151   \n",
       "12345       4287160193_right_subarticular_stenosis_l1_l2     0.852462   \n",
       "12346       4287160193_right_subarticular_stenosis_l2_l3     0.762293   \n",
       "12347       4287160193_right_subarticular_stenosis_l3_l4     0.368856   \n",
       "12348       4287160193_right_subarticular_stenosis_l4_l5     0.686898   \n",
       "12349       4287160193_right_subarticular_stenosis_l5_s1     0.959792   \n",
       "\n",
       "       moderate    severe  \n",
       "12325  0.003336  0.000438  \n",
       "12326  0.089195  0.005119  \n",
       "12327  0.007947  0.000809  \n",
       "12328  0.004481  0.001100  \n",
       "12329  0.003043  0.000933  \n",
       "12330  0.017670  0.000692  \n",
       "12331  0.481502  0.013395  \n",
       "12332  0.424442  0.010512  \n",
       "12333  0.323651  0.012910  \n",
       "12334  0.066542  0.004220  \n",
       "12335  0.058910  0.001863  \n",
       "12336  0.111197  0.002995  \n",
       "12337  0.635083  0.016581  \n",
       "12338  0.513011  0.018059  \n",
       "12339  0.045374  0.003478  \n",
       "12340  0.021780  0.002933  \n",
       "12341  0.607388  0.251342  \n",
       "12342  0.304879  0.024965  \n",
       "12343  0.227746  0.018682  \n",
       "12344  0.031726  0.005124  \n",
       "12345  0.137338  0.010200  \n",
       "12346  0.223498  0.014209  \n",
       "12347  0.539441  0.091703  \n",
       "12348  0.285190  0.027912  \n",
       "12349  0.035685  0.004524  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(all_preds, 0).astype(np.float64)\n",
    "studies = df_2[[\"study_id\"]].copy().astype(int)\n",
    "\n",
    "rows = []\n",
    "for i in range(len(studies)):\n",
    "    for c, injury in enumerate(config_2.targets):\n",
    "        rows.append(\n",
    "            {\n",
    "                \"row_id\": f'{studies[\"study_id\"].values[i]}_{injury}',\n",
    "                \"normal_mild\": preds[i, c, 0],\n",
    "                \"moderate\": preds[i, c, 1],\n",
    "                \"severe\": preds[i, c, 2],\n",
    "            }\n",
    "        )\n",
    "\n",
    "sub = pd.DataFrame(rows)\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- scs_loss\t: 0.364\n",
      "- nfn_loss\t: 0.484\n",
      "- ss_loss\t: 0.558\n",
      "- any_loss\t: 0.471\n",
      "\n",
      " -> CV Score : 0.469\n"
     ]
    }
   ],
   "source": [
    "if EVAL:\n",
    "    y = pd.read_csv(ROOT_DATA_DIR + \"train.csv\")\n",
    "\n",
    "    for c in y.columns[1:]:\n",
    "        y[c] = y[c].map(dict(zip(SEVERITIES, [0, 1, 2]))).fillna(-1)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    df_val = studies.copy().merge(y, how=\"left\")\n",
    "\n",
    "    avg_loss, losses = rsna_loss(df_val[config_2.targets].values, preds)\n",
    "\n",
    "    for k, v in losses.items():\n",
    "        print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "    print(f\"\\n -> CV Score : {avg_loss :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- scs_loss\t: 0.324\n",
      "- nfn_loss\t: 0.484\n",
      "- ss_loss\t: 0.558\n",
      "- any_loss\t: 0.384\n",
      "\n",
      " -> CV Score : 0.438\n"
     ]
    }
   ],
   "source": [
    "if EVAL:\n",
    "    y = pd.read_csv(ROOT_DATA_DIR + \"train.csv\")\n",
    "\n",
    "    for c in y.columns[1:]:\n",
    "        y[c] = y[c].map(dict(zip(SEVERITIES, [0, 1, 2]))).fillna(-1)\n",
    "    y = y.astype(int)\n",
    "\n",
    "    df_val = studies.copy().merge(y, how=\"left\")\n",
    "\n",
    "    avg_loss, losses = rsna_loss(df_val[config_2.targets].values, preds)\n",
    "\n",
    "    for k, v in losses.items():\n",
    "        print(f\"- {k}_loss\\t: {v:.3f}\")\n",
    "\n",
    "    print(f\"\\n -> CV Score : {avg_loss :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
