{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fefbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6ad4e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-12T16:03:00.516834Z",
     "iopub.status.busy": "2023-08-12T16:03:00.516342Z",
     "iopub.status.idle": "2023-08-12T16:03:02.824246Z",
     "shell.execute_reply": "2023-08-12T16:03:02.823119Z"
    },
    "papermill": {
     "duration": 2.317669,
     "end_time": "2023-08-12T16:03:02.827155",
     "exception": false,
     "start_time": "2023-08-12T16:03:00.509486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d620e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "\n",
    "from data.dataset import *\n",
    "from data.transforms import *\n",
    "from data.preparation import *\n",
    "from data.sagital_to_axial import get_axial_coords\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from util.torch import load_model_weights\n",
    "from util.plots import *\n",
    "\n",
    "from inference.lvl1 import Config, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca0ec4",
   "metadata": {},
   "source": [
    "## Sagittal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eccccf",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"../logs/2024-08-28/13/\"  # coatnet_rmlp_2_rw_384 50 ep new folds\n",
    "EXP_FOLDER = \"../logs/2024-08-28/24/\"  # coatnet_rmlp_2_rw_384 aug 50 ep new folds\n",
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))\n",
    "\n",
    "df = prepare_coords_data(config.coords_folder, use_ext=config.use_ext)\n",
    "\n",
    "folds = pd.read_csv(config.folds_file)\n",
    "df = df.merge(folds, how=\"left\")\n",
    "df['fold'] = df['fold'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_sag = []\n",
    "for fold in range(4):\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        pooling=config.pooling,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        pretrained=False,\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "\n",
    "    weights = EXP_FOLDER + f\"{config.name}_{fold}.pt\"\n",
    "    try:\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    # models_sag.append(model)\n",
    "\n",
    "    df_val = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset = CoordsDataset(df_val, transforms=get_transfos(augment=False, resize=config.resize, use_keypoints=True))\n",
    "\n",
    "    preds, _ = predict(model, dataset, config.loss_config, batch_size=32, use_fp16=True)\n",
    "\n",
    "    np.save(EXP_FOLDER + f\"pred_inf_{fold}.npy\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce921ddc",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76563826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = pd.read_csv('../input/train_label_coordinates.csv')\n",
    "\n",
    "# cc = cc.merge(\n",
    "#     cc[[\"series_id\", \"level\"]].groupby(\"series_id\").count().reset_index(),\n",
    "#     how=\"left\",\n",
    "#     on=\"series_id\",\n",
    "#     suffixes=(\"\", \"_count\"),\n",
    "# )\n",
    "\n",
    "# dfg = (\n",
    "#     cc[(cc.condition != \"Spinal Canal Stenosis\") & ~(cc.level_count.isin([5, 10]))]\n",
    "#     .groupby([\"study_id\", \"series_id\"])\n",
    "#     .agg(list)\n",
    "#     .reset_index()\n",
    "# )\n",
    "# dfg.shape\n",
    "\n",
    "# dfg = (\n",
    "#     cc[(cc.condition == \"Spinal Canal Stenosis\") & (cc.level_count != 5)]\n",
    "#     .sort_values(\"level\")\n",
    "#     .groupby([\"study_id\", \"series_id\"])\n",
    "#     .agg(list)\n",
    "#     .reset_index()\n",
    "# )\n",
    "# dfg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db78c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = prepare_data()\n",
    "df_sev = prepare_data_crop(DATA_PATH)\n",
    "df_spinenet = pd.read_csv('../output/spinenet_kps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "df_ = prepare_data()\n",
    "\n",
    "for fold in range(4):\n",
    "    preds = np.load(EXP_FOLDER + f\"pred_inf_{fold}.npy\")\n",
    "    df_val = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    dataset = CoordsDataset(df_val, transforms=get_transfos(augment=False, use_keypoints=True))\n",
    "\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        study = df_val['study_id'][idx]\n",
    "        series = df_val['series_id'][idx]\n",
    "\n",
    "        # if df_val['series_description'][idx] != \"Sagittal T2/STIR\":\n",
    "        #     continue\n",
    "\n",
    "        # if not series in SERIES:  # 2433314690:\n",
    "        #     continue\n",
    "        # if series != 2433314690:\n",
    "        #     continue\n",
    "\n",
    "        img, y, _ = dataset[idx]\n",
    "        labels = np.vstack(df_sev[df_sev['series_id'] == series].sort_values('level')['target'].values)\n",
    "\n",
    "        gt = df_gt[df_gt['series_id'] == series]\n",
    "        imgs = np.load(f'../input/npy/{study}_{series}.npy')\n",
    "\n",
    "        # print(gt['coords'].values[0][:, 0])\n",
    "        # frame = int(np.round(gt['coords'].values[0][:, 0].mean()))\n",
    "        frame = len(imgs) // 2\n",
    "        # frame = len(imgs) // 4\n",
    "        # frame = int(gt['coords'].values[0][-1, 0])\n",
    "\n",
    "        img = imgs[frame]\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "        try:\n",
    "            spinenet_coords = df_spinenet[df_spinenet['series_id'] == series]\n",
    "            spinenet_coords = spinenet_coords.values[len(spinenet_coords)  // 2, -10:].reshape(2, 5).T\n",
    "            # p = spinenet_coords.copy()\n",
    "            # p[:, 0] /= img.shape[1]\n",
    "            # p[:, 1] /= img.shape[0]\n",
    "        except:\n",
    "            spinenet_coords = None\n",
    "\n",
    "        p_ = preds[idx].reshape(-1, 2)\n",
    "\n",
    "        p = preds[idx].reshape(-1, 2)\n",
    "\n",
    "        d = np.abs(p - y.numpy()) * 100\n",
    "        d = d[y.sum(-1) > 0].mean()\n",
    "\n",
    "        # if (y.sum(-1) > 0 ).sum() != 5:\n",
    "        #     print(y)\n",
    "        ds.append(d)\n",
    "\n",
    "        # if d < 4:\n",
    "        #     continue\n",
    "        # print(df_val[\"series_id\"][idx])\n",
    "\n",
    "        if PLOT:\n",
    "            if d > 5:\n",
    "                y = y[y.sum(-1) > 0]\n",
    "                # if len(y) == 5:\n",
    "                #     continue\n",
    "\n",
    "                print(study, series)\n",
    "                # print('SCS / L-NFN / R-NFN / L-SS / R-SS')\n",
    "                # print(labels)\n",
    "\n",
    "                # cv2.imwrite(f'../output/fix/{study}_{series}.png', (img * 255).astype(np.uint8))\n",
    "\n",
    "                plt.figure(figsize=(8, 8))\n",
    "                plt.imshow(img, cmap=\"gray\")\n",
    "                plt.scatter(y[:, 0] * img.shape[1], y[:, 1] * img.shape[0], marker=\"x\", label=\"truth\")\n",
    "                plt.scatter(p_[:, 0] * img.shape[1], p_[:, 1] * img.shape[0], marker=\"x\", label=\"pred\")\n",
    "                if spinenet_coords is not None:\n",
    "                    plt.scatter(spinenet_coords[:, 0], spinenet_coords[:, 1], marker=\"x\", label=\"spinenet\")\n",
    "                plt.title(f'Dist = {d:.2f} - series {series}')\n",
    "                plt.axis(False)\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(p_[:, 0] * img.shape[1], p_[:, 1] * img.shape[0])\n",
    "\n",
    "            # if idx > 50:\n",
    "            #     break\n",
    "    # if PLOT:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Images with error > 5%:', (np.array(ds) > 5).sum())\n",
    "print('Images with error > 4%:', (np.array(ds) > 4).sum())\n",
    "print('Images with error > 3%:', (np.array(ds) > 3).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc35bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(ds)\n",
    "plt.axvline(np.mean(ds), c=\"salmon\")\n",
    "plt.text(np.mean(ds), 100, f\"   mean={np.mean(ds):.3f}\", color=\"salmon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64045e0",
   "metadata": {},
   "source": [
    "### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f88900",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 0.1\n",
    "\n",
    "SAVE = True\n",
    "PLOT = False\n",
    "\n",
    "SAVE_FOLDER = f\"../input/coords_crops_{DELTA}_/\"\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(4):\n",
    "    pred_val = np.load(EXP_FOLDER + f\"pred_inf_{fold}.npy\")\n",
    "    df_val = df[df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    for idx in tqdm(range(len(df_val))):\n",
    "        study_series = df_val[\"img_path\"][idx].split('/')[-1][:-4]\n",
    "        imgs_path = DATA_PATH + \"npy/\" + study_series + \".npy\"\n",
    "        imgs = np.load(imgs_path)\n",
    "\n",
    "        preds = pred_val[idx].reshape(-1, 2)\n",
    "\n",
    "        crops = np.concatenate([preds, preds], -1)\n",
    "        crops[:, [0, 1]] -= DELTA\n",
    "        crops[:, [2, 3]] += DELTA\n",
    "        crops[:, [0, 2]] *= imgs.shape[2]\n",
    "        crops[:, [1, 3]] *= imgs.shape[1]\n",
    "        crops = crops.astype(int)\n",
    "\n",
    "\n",
    "        # print(df_val[\"series_id\"][idx])\n",
    "\n",
    "        if SAVE:\n",
    "            for i, (x0, y0, x1, y1) in enumerate(crops):\n",
    "                crop = imgs[:, y0: y1, x0: x1].copy()\n",
    "                np.save(SAVE_FOLDER + f'{study_series}_{LEVELS_[i]}.npy', crop)\n",
    "\n",
    "                # cc = np.load(SAVE_FOLDER + study_series + \"_\" + LEVELS_[i] + \".npy\")\n",
    "                # plt.imshow(cc[len(cc) // 2], cmap=\"gray\")\n",
    "                # plt.show()\n",
    "\n",
    "        if PLOT:\n",
    "            preds[:, 0] *= imgs.shape[2]\n",
    "            preds[:, 1] *= imgs.shape[1]\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(imgs[len(imgs) // 2], cmap=\"gray\")\n",
    "            plt.scatter(preds[:, 0], preds[:, 1], marker=\"x\", label=\"center\")\n",
    "            plt.scatter(crops[:, 0], crops[:, 1], marker=\"x\", label=\"top-left\")\n",
    "            plt.scatter(crops[:, 2], crops[:, 3], marker=\"x\", label=\"bot-right\")\n",
    "            plt.title(study_series)\n",
    "            plt.axis(False)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b8c6d",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b7560",
   "metadata": {},
   "source": [
    "## Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_studies = [\n",
    "    # 113758629,\n",
    "    # 13317052, 60612428, 74294498, 142991438, \n",
    "    # 168833126, 189360935, 58813022, 1115952008, 959290081,\n",
    "    2388577668  # bugged\n",
    "]\n",
    "\n",
    "PLOT = False\n",
    "SAVE = True\n",
    "\n",
    "SIZE = 0.15\n",
    "SAVE_FOLDER = f\"../input/crops_ax_{SIZE}/\"\n",
    "\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER_AX = \"../logs/2024-08-26/3/\"\n",
    "\n",
    "config = Config(json.load(open(EXP_FOLDER_AX + \"config.json\", \"r\")))\n",
    "\n",
    "models_ax = []\n",
    "for fold in range(4):\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        pooling=config.pooling,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        pretrained=False,\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "\n",
    "    weights = EXP_FOLDER_AX + f\"{config.name}_{fold}.pt\"\n",
    "    model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    models_ax.append(model)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a56ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_coords_data()\n",
    "\n",
    "folds = pd.read_csv(config.folds_file)\n",
    "df = df.merge(folds, how=\"left\")\n",
    "df['fold'] = df['fold'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = prepare_data()\n",
    "df_coords = pd.read_csv(DATA_PATH + \"train_label_coordinates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "axial_coords = []\n",
    "\n",
    "for fold in range(4):\n",
    "    preds_coords = np.load(EXP_FOLDER + f\"pred_val_{fold}.npy\")\n",
    "    df_val = df[df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    for idx in tqdm(range(len(df_val))):\n",
    "        study = df_val[\"study_id\"][idx]\n",
    "        series = df_val[\"series_id\"][idx]\n",
    "\n",
    "        # if not study in ref_studies:\n",
    "        #     continue\n",
    "\n",
    "        # Get axial projection\n",
    "        p = preds_coords[idx].reshape(-1, 2)\n",
    "\n",
    "        img = cv2.imread(df_val[\"img_path\"][idx])\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        world_point, assigned_level, closest_z, df_axial = get_axial_coords(\n",
    "            study,\n",
    "            series,\n",
    "            p.copy(),\n",
    "            h,\n",
    "            w,\n",
    "            df_,\n",
    "            \"../input/train_images/\",\n",
    "        )\n",
    "\n",
    "        if closest_z.max() == 0:  # Fix\n",
    "            world_point[:, -1] -= (world_point[:, -1].mean() - df_axial.projection.mean())\n",
    "            world_point, assigned_level, closest_z, df_axial = get_axial_coords(\n",
    "                study,\n",
    "                series,\n",
    "                p.copy(),\n",
    "                h,\n",
    "                w,\n",
    "                df_,\n",
    "                \"../input/train_images/\",\n",
    "                world_point=world_point\n",
    "            )\n",
    "\n",
    "        # Evaluate\n",
    "        series_ax = df_axial[\"series_id\"].values[0]\n",
    "        df_gt = df_coords[df_coords[\"series_id\"] == series_ax].reset_index(drop=True)\n",
    "        df_gt = df_gt[[\"instance_number\", \"level\", \"x\", \"y\"]].groupby(\"level\").mean().sort_index()\n",
    "        gt = df_gt[\"instance_number\"].values.flatten()\n",
    "        preds = df_axial[\"instance_number\"].values[closest_z]\n",
    "\n",
    "        if len(df_gt) == 5:\n",
    "            mae = np.abs(gt - preds).mean()\n",
    "            # df_gt[\"pred\"] = preds\n",
    "        else:\n",
    "            mae = 0\n",
    "\n",
    "        # Locate disk\n",
    "        imgs = np.load(f'../input/npy2/{study}_{series_ax}.npy')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.tensor(imgs[closest_z].astype(np.float32)).cuda()\n",
    "\n",
    "            min_ = x.amin((-1, -2), keepdim=True)\n",
    "            max_ = x.amax((-1, -2), keepdim=True)\n",
    "            x = (x - min_) / (max_ - min_)\n",
    "            x =  F.interpolate(\n",
    "                x.unsqueeze(1).repeat(1, 3, 1, 1),\n",
    "                config.resize,\n",
    "                mode=\"bilinear\",\n",
    "            )\n",
    "\n",
    "            preds_ax = models_ax[fold](x)[0].sigmoid().detach().cpu().numpy().reshape(x.size(0), 2, 2)\n",
    "\n",
    "        preds_ax[:, :, 0] *= imgs.shape[2]\n",
    "        preds_ax[:, :, 1] *= imgs.shape[1]\n",
    "        \n",
    "        # Crop\n",
    "        crop_imgs = []\n",
    "        for i in range(5):\n",
    "            f = closest_z[i]\n",
    "            fs = max(closest_z[i] - 3, 0)\n",
    "            fe = min(closest_z[i] + 3, len(imgs))\n",
    "\n",
    "            xc, yc = preds_ax[i].mean(0).astype(int)\n",
    "            dx, dy = int(imgs.shape[2] * SIZE), int(imgs.shape[1] * SIZE)\n",
    "            x0, x1 = max(xc - dx, 0), min(xc + dx, imgs.shape[2])\n",
    "            y0, y1 = max(yc - dy, 0), min(yc + dy, imgs.shape[1])\n",
    "\n",
    "            d = SIZE // 2\n",
    "            crop = imgs[fs: fe, y0: y1, x0: x1]\n",
    "            crop_imgs.append(crop[len(crop) // 2])\n",
    "\n",
    "            if SAVE:\n",
    "                np.save(SAVE_FOLDER + f\"{study}_{series_ax}_{LEVELS_[i]}.npy\", crop.copy())\n",
    "\n",
    "        # Plot\n",
    "        if PLOT:\n",
    "            plt.figure(figsize=(25, 5))\n",
    "            for i in range(5):\n",
    "                plt.subplot(1, 5, i + 1)\n",
    "                plt.imshow(crop_imgs[i], cmap=\"gray\")\n",
    "            plt.show()\n",
    "            \n",
    "            # display(df_gt)\n",
    "            # plot_coords(\n",
    "            #     world_point,\n",
    "            #     assigned_level,\n",
    "            #     closest_z,\n",
    "            #     h,\n",
    "            #     w,\n",
    "            #     df_axial,\n",
    "            #     title=f\"Study {study} - Series {series_ax}\",\n",
    "            # )\n",
    "\n",
    "            df_lvl = df_coords[df_coords[\"series_id\"] == series_ax].reset_index(drop=True)\n",
    "            plt.figure(figsize=(25, 5))\n",
    "            for i in range(5):\n",
    "                plt.subplot(1, 5, i + 1)\n",
    "\n",
    "                img = imgs[closest_z[i]]\n",
    "\n",
    "                df_lvl_ = df_lvl[df_lvl[\"level\"] == LEVELS[i]]\n",
    "                x, y = df_lvl_['x'].values, df_lvl_[\"y\"].values\n",
    "\n",
    "                plt.scatter(preds_ax[i, :, 0], preds_ax[i, :, 1], label=\"pred\")\n",
    "                plt.scatter(x, y, label=\"truth\", marker=\"x\")\n",
    "\n",
    "                plt.imshow(img, cmap=\"gray\")\n",
    "                plt.legend()\n",
    "                plt.axis(False)\n",
    "                plt.title(str(df_axial[\"instance_number\"][closest_z[i]]))\n",
    "\n",
    "            plt.show()\n",
    "            if idx > 5:\n",
    "                break\n",
    "    if PLOT:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6677.910014,
   "end_time": "2023-08-12T17:53:47.148086",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-12T16:02:29.238072",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
